{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat coords.csv | awk -vFPAT='([^,]*)|(\"[^\"]+\")' -vOFS=, '{if($1==981 || $1==982) print }' > sample_981_982.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import LineString, Point, MultiPoint\n",
    "import uuid\n",
    "from geographiclib.geodesic import Geodesic\n",
    "from haversine import haversine,Unit\n",
    "from shapely.geometry import Point\n",
    "from shapely import ops\n",
    "import math\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare all groups --> Identify spatial intersections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('coords.csv',header=None, names=['id','time','lat','lon','preds','c1','c2','linestring'])\n",
    "data = data.drop(columns=['preds','c1','c2','linestring'])\n",
    "def calc_speed(data):\n",
    "    data['lag_lon']= data['lon'].shift(1)\n",
    "    data['lag_lat']= data['lat'].shift(1)\n",
    "    data['ddt'] = data['time'].diff().fillna(method='backfill')/1000\n",
    "    data['course'] = data.apply(lambda x: Geodesic.WGS84.Inverse(x.lag_lat,x.lag_lon,x.lat,x.lon)['azi2'],axis=1).fillna(method='backfill')\n",
    "    data['speed'] = data.apply(lambda x: ((Geodesic.WGS84.Inverse(x.lag_lat,x.lag_lon,x.lat,x.lon)['s12'])/x.ddt)*1.9438452 ,axis=1).fillna(method='backfill')\n",
    "    data['course'] = data['course'].apply(lambda x: (x+360)%360)\n",
    "    data['heading']= data['course']\n",
    "\n",
    "# data = data.rename(columns={'lat':'lon', 'lon':'lat'})\n",
    "data[['lon','lat']] = data[['lat','lon']]\n",
    "groups = data.sort_values(['id','time'],ascending=True).groupby(by='id')\n",
    "data_all = pd.DataFrame(columns=['id','time','lon','lat','coll_id'])\n",
    "cnt=0\n",
    "collisions_df = pd.DataFrame(columns=['id1','id2','x','y','t'])\n",
    "\n",
    "\n",
    "def get_closest(data, x, y):\n",
    "    distances = np.sqrt((data['lon'] - x)**2 + (data['lat'] - y)**2)\n",
    "    closest_idx = distances.idxmin()\n",
    "    return distances[closest_idx],closest_idx \n",
    "\n",
    "for g1 in groups:\n",
    "    coordinates1 = list(zip(g1[1]['lat'], g1[1]['lon']))\n",
    "    if len(coordinates1)>1:\n",
    "        line1 = LineString(coordinates=coordinates1)\n",
    "    else:\n",
    "        continue\n",
    "    for g2 in groups:\n",
    "        if g1[0] > g2[0]:\n",
    "            coordinates2 = list(zip(g2[1]['lat'], g2[1]['lon']))\n",
    "            if len(coordinates2)>1:\n",
    "                line2 = LineString(coordinates=coordinates2)\n",
    "                if line1.intersects(line2) and g1[1].shape[0]>2 and g2[1].shape[0]>2:\n",
    "                    cnt+=1\n",
    "                    inter = line1.intersection(line2)\n",
    "                    if inter.geom_type == 'Point':\n",
    "                        x, y = inter.x, inter.y\n",
    "                    elif inter.geom_type == 'MultiPoint':\n",
    "                        point = inter.geoms[0]\n",
    "                        x, y = point.x, point.y\n",
    "                    \n",
    "                    # Assign collision IDs\n",
    "                    coll_id = cnt #uuid.uuid4()\n",
    "                    g1[1]['coll_id'] = coll_id\n",
    "                    g2[1]['coll_id'] = coll_id\n",
    "\n",
    "                    # Calculate speeds, Knots/sec\n",
    "                    calc_speed(g1[1])\n",
    "                    calc_speed(g2[1])\n",
    "                    \n",
    "                    \n",
    "                    dist_a, a_index  = get_closest(coordinates1,x,y)\n",
    "                    dist_c, c_index  = get_closest(coordinates2,x,y)\n",
    "                    kdt1 = KDTree(coordinates1)\n",
    "                    nearest_dist, nearest_ind  = kdt1.query([[x,y]],k=2)\n",
    "                    a_index1 = nearest_ind[0][0]\n",
    "                    a_index2 = nearest_ind[0][1]\n",
    "                    a_index = a_index1 if g1[1]['time'].iloc[a_index1] <  g1[1]['time'].iloc[a_index2] else a_index2\n",
    "                    \n",
    "                    \n",
    "                    kdt2 = KDTree(coordinates2)\n",
    "                    nearest_dist2, nearest_ind2  = kdt2.query([[x,y]],k=2)\n",
    "                    c_index1 = nearest_ind2[0][0]\n",
    "                    c_index2 = nearest_ind2[0][1]\n",
    "                    c_index = c_index1 if g2[1]['time'].iloc[c_index1] <  g2[1]['time'].iloc[c_index2] else c_index2\n",
    "                    \n",
    "                    # Calculate time aligment\n",
    "                    crush_point = Point(x,y)\n",
    "                    a = Point(g1[1]['lat'].iloc[a_index], g1[1]['lon'].iloc[a_index])\n",
    "                    # Meters\n",
    "                    ax = Geodesic.WGS84.Inverse(a.y,a.x, crush_point.y ,crush_point.x)['s12'] \n",
    "                    # Seconds, speed m/s\n",
    "                    t_crush1 = ax / (g1[1]['speed'].iloc[a_index]/ 1.9438452 )\n",
    "                    # Meters \n",
    "                    c = Point(g2[1]['lat'].iloc[c_index], g2[1]['lon'].iloc[c_index])\n",
    "                    cx = Geodesic.WGS84.Inverse(c.y,c.x, crush_point.y ,crush_point.x)['s12']\n",
    "                    # Meters / m/s\n",
    "                    t_crush2 = cx / (g2[1]['speed'].iloc[c_index] / 1.9438452) \n",
    "                    # dt of ship2\n",
    "                   \n",
    "                    # Offset\n",
    "                    offset = int((g1[1]['time'].iloc[a_index] + t_crush1*1000 ) - ((g2[1]['time'].iloc[c_index]) + t_crush2*1000))\n",
    "                    for i in range(g2[1].shape[0]):\n",
    "                        g2[1].at[i, 'time'] = g2[1]['time'].iloc[i]\n",
    "                        g2[1].at[i, 'new_time'] = g2[1]['time'].iloc[i] - 2*offset\n",
    "                    \n",
    "                     \n",
    "                    g2[1]['time'] =  g2[1]['time'] \n",
    "                    g2[1]['new_time'] =  g2[1]['time'] + offset\n",
    "\n",
    "                    g1[1]['new_time'] = g1[1]['time']\n",
    "                    temp = pd.DataFrame(data={'id1':g1[0], 'id2':g2[0],'x':x,'y':y,'t':0}, index=[0])\n",
    "                    collisions_df = pd.concat([collisions_df, temp]).reset_index(drop=True)\n",
    "                    data_all = pd.concat([data_all,g1[1],g2[1]])\n",
    "            else:\n",
    "                continue\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time align pair per spatial intersection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_row(data):\n",
    "    data['lag_lon']= data['lon'].shift(1)\n",
    "    data['lag_lat']= data['lat'].shift(1)\n",
    "    data['ddt'] = data['time'].diff().fillna(method='backfill')/1000\n",
    "    data['course'] = data.apply(lambda x: Geodesic.WGS84.Inverse(x.lag_lat,x.lag_lon,x.lat,x.lon)['azi2'],axis=1).fillna(method='backfill')\n",
    "    data['speed'] = data.apply(lambda x: ((Geodesic.WGS84.Inverse(x.lag_lat,x.lag_lon,x.lat,x.lon)['s12'])/x.ddt)*1.9438452 ,axis=1).fillna(method='backfill')\n",
    "    data['course'] = data['course'].apply(lambda x: (x+360)%360)\n",
    "    data['heading']= data['course']        \n",
    "            \n",
    "data_all = pd.DataFrame(columns=['id','time','lon','lat','coll_id'])\n",
    "collisions_copy = pd.DataFrame(columns=['id1','id2','x','y','t','coll_id'])\n",
    "cnt=0\n",
    "\n",
    "iter_offset = 0 \n",
    "\n",
    "\n",
    "\n",
    "for row in collisions_df.itertuples():\n",
    "    cnt+=1\n",
    "    x= row.x\n",
    "    y=row.y\n",
    "    \n",
    "    g1 = groups.get_group(int(row.id1)).reset_index(drop=True).copy()\n",
    "    g2 = groups.get_group(int(row.id2)).reset_index(drop=True).copy()\n",
    "    \n",
    "    g1['coll_id'] = cnt\n",
    "    g2['coll_id'] = cnt\n",
    "    \n",
    "    coordinates1 = list(zip(g1['lat'], g1['lon']))\n",
    "    coordinates2 = list(zip(g2['lat'], g2['lon']))\n",
    "    \n",
    "    line1 = LineString(coordinates=coordinates1)\n",
    "    line2 = LineString(coordinates=coordinates2)\n",
    "    \n",
    "    update_row(g1)\n",
    "    update_row(g2)\n",
    "    crush_point = Point(x,y)\n",
    "\n",
    "    a_index = 0\n",
    "    for i in range(g1.shape[0]-1):\n",
    "        c1 = list(zip(g1['lat'].iloc[i:i+2], g1['lon'].iloc[i:i+2]))\n",
    "        l1 = LineString(coordinates=c1)\n",
    "        if l1.intersects(crush_point.buffer(0.001)):\n",
    "            a_index = i\n",
    "            # break\n",
    "    c_index = 0\n",
    "    for j in range(g2.shape[0]-1):\n",
    "        c2 = list(zip(g2['lat'].iloc[j:j+2], g2['lon'].iloc[j:j+2]))\n",
    "        l2 = LineString(coordinates=c2)\n",
    "        if l2.intersects(crush_point.buffer(0.001)):\n",
    "            c_index = j\n",
    "            # break\n",
    "    \n",
    "    kdt1 = KDTree(coordinates1)\n",
    "    nearest_dist, nearest_ind  = kdt1.query([[x,y]],k=2)\n",
    "    a_index1 = nearest_ind[0][0]\n",
    "    a_index2 = nearest_ind[0][1]\n",
    "    a_index = a_index1 if g1['time'].iloc[a_index1] <  g1['time'].iloc[a_index2] else a_index2\n",
    "    \n",
    "    \n",
    "    kdt2 = KDTree(coordinates2)\n",
    "    nearest_dist2, nearest_ind2  = kdt2.query([[x,y]],k=2)\n",
    "    c_index1 = nearest_ind2[0][0]\n",
    "    c_index2 = nearest_ind2[0][1]\n",
    "    c_index = c_index1 if g2['time'].iloc[c_index1] <  g2['time'].iloc[c_index2] else c_index2\n",
    "    \n",
    "    # Calculate time aligment\n",
    "    a = Point(g1['lat'].iloc[a_index], g1['lon'].iloc[a_index])\n",
    "    # Meters\n",
    "    ax = Geodesic.WGS84.Inverse(a.y,a.x, crush_point.y ,crush_point.x)['s12'] \n",
    "    # Seconds, speed m/s\n",
    "    t_crush1 = ax / (g1['speed'].iloc[a_index]/ 1.9438452 )\n",
    "    # Meters \n",
    "    c = Point(g2['lat'].iloc[c_index], g2['lon'].iloc[c_index])\n",
    "    cx = Geodesic.WGS84.Inverse(c.y,c.x, crush_point.y ,crush_point.x)['s12']\n",
    "    # Meters / m/s\n",
    "    t_crush2 = cx / (g2['speed'].iloc[c_index] / 1.9438452) \n",
    "    # dt of ship2\n",
    "    \n",
    "    # Offset\n",
    "    offset = int((g1['time'].iloc[a_index] + t_crush1*1000 ) - ((g2['time'].iloc[c_index]) + t_crush2*1000))\n",
    "    \n",
    "    \n",
    "    \n",
    "    crush_time =  g2['time'].iloc[c_index] +iter_offset+ offset\n",
    "    g2['time'] = g2['time'] +iter_offset+ offset\n",
    "    g1['time'] = g1['time'] +iter_offset\n",
    "    \n",
    "    print(g1.id, g2.id)\n",
    "    g1.id = cnt*10 +1 \n",
    "    g2.id = cnt*10 +2\n",
    "    print(g1.id, g2.id)\n",
    "    \n",
    "    t1 = g1['time'].iloc[a_index] \n",
    "\n",
    "    t2 = g2['time'].iloc[c_index]\n",
    "    # print(10*'-')\n",
    "    # print(f\"{g1.id.iloc[0]}, {g2.id.iloc[0]}, {abs(t2-t1)}\")\n",
    "    \n",
    "    # print(10*'-')\n",
    "\n",
    "    data_all = pd.concat([data_all,g1,g2])\n",
    "    \n",
    "    iter_offset+=2*3600*1000\n",
    "    \n",
    "    collisions_copy = pd.concat([collisions_copy,  \\\n",
    "                                  pd.DataFrame(data={'id1':cnt*10 +1, 'id2':cnt*10 +2,'x':x,'y':y,'t':crush_time,\\\n",
    "                                               'coll_id':cnt, 't1':t1, 't2':t2, 't1_crush':t_crush1, 't2_crush':t_crush2, \\\n",
    "                                                'crush1':a_index,'crush1_total':g1.shape[0], 'crush2':c_index,'crush2_total':g2.shape[0]}, index=[0])]).reset_index(drop=True)\n",
    "    \n",
    "collisions_copy['id1'] = collisions_copy['id1'].astype('Int64')\n",
    "collisions_copy['id2'] = collisions_copy['id2'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_copy['expected_diff_nn1'] = abs(((collisions_copy['t1']-collisions_copy['t2'])/60000))\n",
    "collisions_copy['expected_diff_crush'] = abs(((collisions_copy['t1_crush']-collisions_copy['t2_crush'])/60))\n",
    "collisions_copy['missaligment'] = abs(collisions_copy['expected_diff_nn1'] - collisions_copy['expected_diff_crush'])\n",
    "collisions_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard events with under N points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard events with less than 10 points from both \n",
    "a = data_all.groupby(by='id')['lon'].count().sort_values()\n",
    "a = a > 10\n",
    "a = a[a==True].index\n",
    "data_all = data_all[data_all['id'].isin(a)].reset_index(drop=True)\n",
    "collisions_copy = collisions_copy[(collisions_copy['id1'].isin(a))&(collisions_copy['id2'].isin(a))].reset_index(drop=True)\n",
    "# Discard events that collision appear in the first 3 points\n",
    "collisions_copy = collisions_copy[(collisions_copy['crush1']>3)&(collisions_copy['crush2']>3)]\n",
    "cols = pd.concat([collisions_copy['id1'], collisions_copy['id2']])\n",
    "data_all = data_all[data_all['id'].isin(cols)].reset_index(drop=True)\n",
    "collisions_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set threshold here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minutes\n",
    "threshold = 30\n",
    "collisions_copy_ids = collisions_copy[collisions_copy['expected_diff_nn1']< threshold ][['id1','id2']]\n",
    "d = pd.concat([collisions_copy_ids['id1'], collisions_copy_ids['id2']])\n",
    "data_all = data_all[data_all['id'].isin(d)].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Save\n",
    "data_output = pd.DataFrame(columns=['station','mmsi','t','lon','lat','heading','course','speed','status'])\n",
    "data_all['station'] = 1\n",
    "data_all['status'] = 1\n",
    "\n",
    "data_output = data_all[['station','id','time','lon','lat','heading','course','speed','status']]\n",
    "data_output = data_output.rename(columns={\n",
    "    'id':'mmsi',\n",
    "    'time':'t'\n",
    "})\n",
    "data_output = data_output.astype({'station':'int',\n",
    "                'mmsi':'int',\n",
    "                # 't':\"int\",\n",
    "                \"lon\":\"float\",\n",
    "                \"lat\":\"float\",\n",
    "                \"heading\":\"int\",\n",
    "                \"course\":\"int\",\n",
    "                \"speed\":\"int\",\n",
    "                \"status\":\"int\"})\n",
    "data_output = data_output.fillna(value=0).sort_values(by='t', ascending=True).drop_duplicates()\n",
    "data_output.to_csv('collision_sample.csv',index=False)\n",
    "collisions_copy[['x','y']] = collisions_copy[['y','x']]\n",
    "collisions_copy.to_csv('results/collision_true.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
