<?xml version="1.0" encoding="UTF-8"?><process version="10.5.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000" expanded="true" name="Process" origin="GENERATED_TUTORIAL">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve kafka-no-auth" width="90" x="514" y="646">
        <parameter key="repository_entry" value="/Connections/kafka-no-auth"/>
      </operator>
      <operator activated="false" class="kafka_connector:read_kafka_topic" compatibility="0.3.002" expanded="true" height="82" name="Read Kafka Topic" width="90" x="648" y="646">
        <parameter key="kafka_topic" value="UPB-CREXDATA-Flooding-Optimizer-Input"/>
        <parameter key="offset_strategy" value="earliest"/>
        <parameter key="retrieval_time_out" value="5"/>
        <parameter key="get_all" value="true"/>
        <parameter key="number_of_records" value="100"/>
        <parameter key="collection_strategy" value="duration"/>
        <parameter key="counter" value="100"/>
        <parameter key="time_out" value="120"/>
        <parameter key="polling_time_out" value="5"/>
        <parameter key="api_timeout" value="10"/>
        <description align="center" color="transparent" colored="false" width="126">UPB-CREXDATA-Flooding-Optimizer-Input</description>
      </operator>
      <operator activated="true" breakpoints="after" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve Optimizer-Input-Kafka" width="90" x="45" y="34">
        <parameter key="repository_entry" value="Optimizer-Input-Kafka"/>
      </operator>
      <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve kafka-no-auth (2)" width="90" x="112" y="646">
        <parameter key="repository_entry" value="/Connections/kafka-no-auth"/>
      </operator>
      <operator activated="false" class="kafka_connector:read_kafka_topic" compatibility="0.3.002" expanded="true" height="82" name="Read Kafka Topic (2)" width="90" x="246" y="646">
        <parameter key="kafka_topic" value="UPB-CREXDATA-Flooding-Optimizer-Output"/>
        <parameter key="offset_strategy" value="earliest"/>
        <parameter key="retrieval_time_out" value="5"/>
        <parameter key="get_all" value="true"/>
        <parameter key="number_of_records" value="100"/>
        <parameter key="collection_strategy" value="duration"/>
        <parameter key="counter" value="100"/>
        <parameter key="time_out" value="120"/>
        <parameter key="polling_time_out" value="5"/>
        <parameter key="api_timeout" value="10"/>
        <description align="center" color="transparent" colored="false" width="126">UPB-CREXDATA-Flooding-Optimizer-Input</description>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="82" name="Execute Python" width="90" x="715" y="187">
        <parameter key="script" value="import pandas&#10;&#10;# rm_main is a mandatory function, &#10;# the number of arguments has to be the number of input ports (can be none),&#10;#     or the number of input ports plus one if &quot;use macros&quot; parameter is set&#10;# if you want to use macros, use this instead and check &quot;use macros&quot; parameter:&#10;#def rm_main(data,macros):&#10;def rm_main(data):&#10;    print('Hello, world!')&#10;    # output can be found in Log View&#10;    print(type(data))&#10;&#10;    #your code goes here&#10;&#10;    #for example:&#10;    data2 = pandas.DataFrame([3,5,77,8])&#10;&#10;    # connect 2 output ports to see the results&#10;    return data, data2"/>
        <parameter key="script_file" value="/Users/evyshka/Documents/AltairRapidMiner/AI Studio/Projects/ncsr-optimizer-integration/NCSR-Optimizer/ga-generic-test.py"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <operator activated="false" class="subprocess" compatibility="10.5.000" expanded="true" height="82" name="Subprocess" width="90" x="715" y="289">
        <process expanded="true">
          <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="82" name="Create Rainfall event" width="90" x="782" y="136">
            <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(data):&#10;    &quot;&quot;&quot;&#10;    Main function for RapidMiner Execute Python operator.&#10;    &#10;    Args:&#10;        data: Input data (can be a pandas DataFrame or dict)&#10;    &#10;    Returns:&#10;        pandas.DataFrame: DataFrame containing the rainfall_event_id&#10;    &quot;&quot;&quot;&#10;    # If data is a DataFrame, extract the actual data&#10;    if isinstance(data, pd.DataFrame):&#10;        if len(data) == 0:&#10;            raise ValueError(&quot;Input DataFrame is empty&quot;)&#10;        &#10;        # Check if there's a 'value' column (Kafka message format)&#10;        if 'value' in data.columns:&#10;            json_str = data.iloc[-1]['value']&#10;            input_data = json.loads(json_str)&#10;        else:&#10;            # Try to parse the first column&#10;            json_str = data.iloc[0, 0]&#10;            try:&#10;                input_data = json.loads(json_str)&#10;            except (json.JSONDecodeError, TypeError):&#10;                # Last resort: convert row to dict&#10;                input_data = data.iloc[-1].to_dict()&#10;    else:&#10;        # If input is already a dict (like from Kafka)&#10;        if isinstance(data, dict) and 'value' in data:&#10;            # Parse the JSON string in the 'value' field&#10;            input_data = json.loads(data['value'])&#10;        else:&#10;            input_data = data&#10;    &#10;    result_df = send_rainfall_event(input_data)&#10;    return result_df&#10;&#10;def send_rainfall_event(input_data):&#10;    &quot;&quot;&quot;&#10;    Send rainfall event data to the API and return the rainfall_event_id.&#10;    &#10;    Args:&#10;        input_data: Dictionary containing the rainfall event data&#10;    &#10;    Returns:&#10;        pandas.DataFrame: DataFrame with rainfall_event_id and other metadata&#10;    &quot;&quot;&quot;&#10;    # Configuration&#10;    API_BASE_URL = &quot;https://api.floodwaive.de/v1&quot;&#10;    &#10;    # Area ID mapping&#10;    AREA_IDS = {&#10;        &quot;Dortmund&quot;: &quot;20250519130422&quot;,&#10;        &quot;Innsbruck&quot;: &quot;20250913133225&quot;&#10;    }&#10;    &#10;    # API Authentication&#10;    API_TOKEN = &quot;fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;&#10;    &#10;    # Get the area from the input data and map to area ID&#10;    area_name = input_data.get(&quot;area&quot;)&#10;    &#10;    if area_name is None:&#10;        raise ValueError(f&quot;'area' field not found in input data. Available keys: {list(input_data.keys())}&quot;)&#10;    &#10;    AREA_ID = AREA_IDS.get(area_name)&#10;    &#10;    if AREA_ID is None:&#10;        raise ValueError(f&quot;Unknown area: {area_name}. Supported areas: {list(AREA_IDS.keys())}&quot;)&#10;    &#10;    print(f&quot;Detected Area: {area_name}&quot;)&#10;    print(f&quot;Using Area ID: {AREA_ID}&quot;)&#10;    &#10;    # Build the API endpoint&#10;    endpoint = f&quot;{API_BASE_URL}/areas/area_{AREA_ID}/rainfall-events&quot;&#10;    &#10;    # Transform the rainfall intervals to match the API format&#10;    rainfall_values = [&#10;        {&#10;            &quot;duration&quot;: interval[&quot;duration&quot;],&#10;            &quot;intensity&quot;: interval[&quot;intensity&quot;]&#10;        }&#10;        for interval in input_data[&quot;rainfallEvent&quot;][&quot;rainfallIntervals&quot;]&#10;    ]&#10;    &#10;    # Prepare the request body&#10;    request_body = {&#10;        &quot;name&quot;: input_data[&quot;rainfallEvent&quot;][&quot;name&quot;],&#10;        &quot;rainfall_values&quot;: rainfall_values,&#10;        &quot;description&quot;: &quot;Test Description&quot;&#10;    }&#10;    &#10;    # Prepare headers with authentication&#10;    headers = {&#10;        &quot;Content-Type&quot;: &quot;application/json&quot;,&#10;        &quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;&#10;    }&#10;    &#10;    # Print the request details&#10;    print(&quot;=&quot; * 60)&#10;    print(&quot;API Request Details&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    print(f&quot;Endpoint: {endpoint}&quot;)&#10;    print(f&quot;Authentication: Bearer Token&quot;)&#10;    print(f&quot;\nRequest Body:&quot;)&#10;    print(json.dumps(request_body, indent=2))&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    # Send the POST request&#10;    try:&#10;        response = requests.post(&#10;            endpoint,&#10;            json=request_body,&#10;            headers=headers&#10;        )&#10;        &#10;        # Print response details&#10;        print(f&quot;\nResponse Status Code: {response.status_code}&quot;)&#10;        &#10;        # Check if request was successful&#10;        if response.status_code in [200, 201]:&#10;            print(&quot;✓ Request successful!&quot;)&#10;            &#10;            # Parse the response JSON&#10;            response_data = response.json()&#10;            &#10;            # Create DataFrame with key information&#10;            result_df = pd.DataFrame([{&#10;                &quot;rainfall_event_id&quot;: response_data.get(&quot;rainfall_event_id&quot;),&#10;                &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: response_data.get(&quot;area_id&quot;),&#10;                &quot;created_at&quot;: response_data.get(&quot;created_at&quot;),&#10;                &quot;status&quot;: &quot;success&quot;,&#10;                &quot;status_code&quot;: response.status_code&#10;            }])&#10;            &#10;            print(f&quot;\nRainfall Event ID: {response_data.get('rainfall_event_id')}&quot;)&#10;            &#10;            return result_df&#10;        else:&#10;            print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;            &#10;            # Return error DataFrame&#10;            error_df = pd.DataFrame([{&#10;                &quot;rainfall_event_id&quot;: None,&#10;                &quot;name&quot;: request_body.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: f&quot;area_{AREA_ID}&quot;,&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;failed&quot;,&#10;                &quot;status_code&quot;: response.status_code,&#10;                &quot;error_message&quot;: response.text&#10;            }])&#10;            &#10;            return error_df&#10;            &#10;    except requests.exceptions.RequestException as e:&#10;        print(f&quot;✗ Error sending request: {e}&quot;)&#10;        &#10;        # Return error DataFrame&#10;        error_df = pd.DataFrame([{&#10;            &quot;rainfall_event_id&quot;: None,&#10;            &quot;name&quot;: request_body.get(&quot;name&quot;),&#10;            &quot;area_id&quot;: f&quot;area_{AREA_ID}&quot;,&#10;            &quot;created_at&quot;: None,&#10;            &quot;status&quot;: &quot;error&quot;,&#10;            &quot;status_code&quot;: None,&#10;            &quot;error_message&quot;: str(e)&#10;        }])&#10;        &#10;        return error_df&#10;"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="82" name="Create Measures" width="90" x="380" y="136">
            <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(data):&#10;    &quot;&quot;&quot;&#10;    Main function for RapidMiner Execute Python operator.&#10;    &#10;    Args:&#10;        data: Input data (can be a pandas DataFrame or dict)&#10;    &#10;    Returns:&#10;        pandas.DataFrame: DataFrame containing the measure_id&#10;    &quot;&quot;&quot;&#10;    # If data is a DataFrame, extract the actual data&#10;    if isinstance(data, pd.DataFrame):&#10;        if len(data) == 0:&#10;            raise ValueError(&quot;Input DataFrame is empty&quot;)&#10;        &#10;        # Check if there's a 'value' column (Kafka message format)&#10;        if 'value' in data.columns:&#10;            json_str = data.iloc[-1]['value']&#10;            input_data = json.loads(json_str)&#10;        else:&#10;            # Try to parse the first column&#10;            json_str = data.iloc[0, 0]&#10;            try:&#10;                input_data = json.loads(json_str)&#10;            except (json.JSONDecodeError, TypeError):&#10;                # Last resort: convert row to dict&#10;                input_data = data.iloc[-1].to_dict()&#10;    else:&#10;        # If input is already a dict (like from Kafka)&#10;        if isinstance(data, dict) and 'value' in data:&#10;            # Parse the JSON string in the 'value' field&#10;            input_data = json.loads(data['value'])&#10;        else:&#10;            input_data = data&#10;    &#10;    result_df = create_measures(input_data)&#10;    return result_df&#10;&#10;def create_measures(input_data):&#10;    &quot;&quot;&quot;&#10;    Create measures (barriers) via the API and return the measure_ids.&#10;    &#10;    Args:&#10;        input_data: Dictionary containing the barrier data&#10;    &#10;    Returns:&#10;        pandas.DataFrame: DataFrame with measure_id and other metadata for each barrier&#10;    &quot;&quot;&quot;&#10;    # Configuration&#10;    API_BASE_URL = &quot;https://api.floodwaive.de/v1&quot;&#10;    &#10;    # Area ID mapping&#10;    AREA_IDS = {&#10;        &quot;Dortmund&quot;: &quot;20250519130422&quot;,&#10;        &quot;Innsbruck&quot;: &quot;20250913133225&quot;&#10;    }&#10;    &#10;    # API Authentication&#10;    API_TOKEN = &quot;fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;&#10;    &#10;    # Get the area from the input data and map to area ID&#10;    area_name = input_data.get(&quot;area&quot;)&#10;    &#10;    if area_name is None:&#10;        raise ValueError(f&quot;'area' field not found in input data. Available keys: {list(input_data.keys())}&quot;)&#10;    &#10;    AREA_ID = AREA_IDS.get(area_name)&#10;    &#10;    if AREA_ID is None:&#10;        raise ValueError(f&quot;Unknown area: {area_name}. Supported areas: {list(AREA_IDS.keys())}&quot;)&#10;    &#10;    print(f&quot;Detected Area: {area_name}&quot;)&#10;    print(f&quot;Using Area ID: {AREA_ID}&quot;)&#10;    &#10;    # Build the API endpoint&#10;    endpoint = f&quot;{API_BASE_URL}/areas/area_{AREA_ID}/measures&quot;&#10;    &#10;    # Prepare headers with authentication&#10;    headers = {&#10;        &quot;Content-Type&quot;: &quot;application/json&quot;,&#10;        &quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;&#10;    }&#10;    &#10;    # Get barriers from input data&#10;    barriers = input_data.get(&quot;barriers&quot;, [])&#10;    &#10;    if not barriers:&#10;        raise ValueError(&quot;No barriers found in input data&quot;)&#10;    &#10;    print(f&quot;\nFound {len(barriers)} barrier(s) to create&quot;)&#10;    &#10;    # Store results for all barriers&#10;    results = []&#10;    &#10;    # Create each barrier&#10;    for idx, barrier in enumerate(barriers, 1):&#10;        print(&quot;\n&quot; + &quot;=&quot; * 60)&#10;        print(f&quot;Creating Barrier {idx}/{len(barriers)}: {barrier.get('name')}&quot;)&#10;        print(&quot;=&quot; * 60)&#10;        &#10;        # Calculate elevation change from minHeight and maxHeight&#10;        # Using maxHeight as the elevation_change&#10;        elevation_change = barrier.get(&quot;maxHeight&quot;, 0)&#10;        &#10;        # Prepare the request body for this barrier&#10;        request_body = {&#10;            &quot;name&quot;: barrier.get(&quot;name&quot;),&#10;            &quot;tag&quot;: barrier.get(&quot;tag&quot;),&#10;            &quot;geometry&quot;: barrier.get(&quot;geometry&quot;),&#10;            &quot;elevation_change&quot;: float(elevation_change),&#10;            &quot;description&quot;: f&quot;Barrier created from optimizer with height {elevation_change}m&quot;&#10;        }&#10;        &#10;        print(f&quot;Request Body:&quot;)&#10;        print(json.dumps(request_body, indent=2))&#10;        &#10;        # Send the POST request&#10;        try:&#10;            response = requests.post(&#10;                endpoint,&#10;                json=request_body,&#10;                headers=headers&#10;            )&#10;            &#10;            # Print response details&#10;            print(f&quot;\nResponse Status Code: {response.status_code}&quot;)&#10;            &#10;            # Check if request was successful&#10;            if response.status_code in [200, 201]:&#10;                print(&quot;✓ Request successful!&quot;)&#10;                &#10;                # Parse the response JSON&#10;                response_data = response.json()&#10;                &#10;                # Add to results&#10;                results.append({&#10;                    &quot;measure_id&quot;: response_data.get(&quot;measure_id&quot;),&#10;                    &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                    &quot;area_id&quot;: response_data.get(&quot;area_id&quot;),&#10;                    &quot;tag&quot;: response_data.get(&quot;tag&quot;),&#10;                    &quot;elevation_change&quot;: response_data.get(&quot;elevation_change&quot;),&#10;                    &quot;created_at&quot;: response_data.get(&quot;created_at&quot;),&#10;                    &quot;status&quot;: &quot;success&quot;,&#10;                    &quot;status_code&quot;: response.status_code&#10;                })&#10;                &#10;                print(f&quot;Measure ID: {response_data.get('measure_id')}&quot;)&#10;                &#10;            else:&#10;                print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;                print(f&quot;Response: {response.text}&quot;)&#10;                &#10;                # Add error to results&#10;                results.append({&#10;                    &quot;measure_id&quot;: None,&#10;                    &quot;name&quot;: request_body.get(&quot;name&quot;),&#10;                    &quot;area_id&quot;: f&quot;area_{AREA_ID}&quot;,&#10;                    &quot;tag&quot;: request_body.get(&quot;tag&quot;),&#10;                    &quot;elevation_change&quot;: request_body.get(&quot;elevation_change&quot;),&#10;                    &quot;created_at&quot;: None,&#10;                    &quot;status&quot;: &quot;failed&quot;,&#10;                    &quot;status_code&quot;: response.status_code,&#10;                    &quot;error_message&quot;: response.text&#10;                })&#10;                &#10;        except requests.exceptions.RequestException as e:&#10;            print(f&quot;✗ Error sending request: {e}&quot;)&#10;            &#10;            # Add error to results&#10;            results.append({&#10;                &quot;measure_id&quot;: None,&#10;                &quot;name&quot;: request_body.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: f&quot;area_{AREA_ID}&quot;,&#10;                &quot;tag&quot;: request_body.get(&quot;tag&quot;),&#10;                &quot;elevation_change&quot;: request_body.get(&quot;elevation_change&quot;),&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;error&quot;,&#10;                &quot;status_code&quot;: None,&#10;                &quot;error_message&quot;: str(e)&#10;            })&#10;    &#10;    # Create DataFrame with all results&#10;    result_df = pd.DataFrame(results)&#10;    &#10;    print(&quot;\n&quot; + &quot;=&quot; * 60)&#10;    print(f&quot;Summary: Created {len([r for r in results if r['status'] == 'success'])}/{len(barriers)} barriers successfully&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    return result_df&#10;&#10;# Standalone execution for testing&#10;if __name__ == &quot;__main__&quot;:&#10;    print(&quot;This script is designed to be used with RapidMiner Execute Python operator.&quot;)&#10;    print(&quot;Call rm_main(data) with your input data.&quot;)&#10;    print(&quot;\nExpected input format:&quot;)&#10;    print(&quot;  - Dictionary with 'value' key containing JSON string&quot;)&#10;    print(&quot;  - OR DataFrame with 'value' column containing JSON string&quot;)&#10;    print(&quot;  - JSON should have keys: 'area', 'barriers'&quot;)&#10;    print(&quot;  - barriers: list of barrier objects with 'name', 'tag', 'geometry', 'minHeight', 'maxHeight'&quot;)&#10;    print(&quot;\nSupported areas: Dortmund, Innsbruck&quot;)"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <portSpacing port="source_in 1" spacing="0"/>
          <portSpacing port="source_in 2" spacing="0"/>
          <portSpacing port="sink_out 1" spacing="0"/>
          <description align="left" color="green" colored="true" height="443" resized="true" width="604" x="30" y="13">&lt;br&gt; &lt;br&gt; curl -X POST https://api.floodwaive.de/v1/areas/area_20250519130422/measures \&lt;br&gt;-H &amp;quot;Authorization: Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&amp;quot; \&lt;br&gt;-H &amp;quot;Content-Type: application/json&amp;quot; \&lt;br&gt;-d '{&lt;br&gt;&amp;quot;name&amp;quot;: &amp;quot;Notebook Test Wall - 20250521182426&amp;quot;,&lt;br&gt;&amp;quot;tag&amp;quot;: &amp;quot;WALL&amp;quot;,&lt;br&gt;&amp;quot;geometry&amp;quot;: {&lt;br&gt;&amp;quot;type&amp;quot;: &amp;quot;Polygon&amp;quot;,&lt;br&gt;&amp;quot;coordinates&amp;quot;: [&lt;br&gt;[&lt;br&gt;[7.459408, 51.486890],&lt;br&gt;[7.459940, 51.485435],&lt;br&gt;[7.459377, 51.485356],&lt;br&gt;[7.458845, 51.486811],&lt;br&gt;[7.459408, 51.486890]&lt;br&gt;]&lt;br&gt;]&lt;br&gt;},&lt;br&gt;&amp;quot;elevation_change&amp;quot;: 10.0,&lt;br&gt;&amp;quot;description&amp;quot;: &amp;quot;A 10.0m high flood wall created via Jupyter Notebook.&amp;quot;&lt;br&gt;}'</description>
          <description align="left" color="purple" colored="true" height="252" resized="true" width="626" x="674" y="377">curl -X POST https://api.floodwaive.de/v1/areas/area_20250913133225/simulations \&lt;br&gt;-H &amp;quot;Authorization: Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&amp;quot; \&lt;br&gt;-H &amp;quot;Content-Type: application/json&amp;quot; \&lt;br&gt;-d '{&lt;br&gt;&amp;quot;name&amp;quot;: &amp;quot;Notebook Test Simulation - 20250521182440&amp;quot;,&lt;br&gt;&amp;quot;model_id&amp;quot;: &amp;quot;deepwaive-4.0-pre-latest&amp;quot;,&lt;br&gt;&amp;quot;resolution&amp;quot;: 4,&lt;br&gt;&amp;quot;rainfall_event_id&amp;quot;: &amp;quot;rainfall-event-8a1c5705-9cf6-4d0b-9da8-553fab3bafc0&amp;quot;,&lt;br&gt;&amp;quot;measures&amp;quot;: [&amp;quot;measure-95268398-a1be-44ba-a30f-d9a52a7b4e1b&amp;quot;]&lt;br&gt;}'</description>
          <description align="left" color="red" colored="true" height="266" resized="true" width="574" x="679" y="69">curl -X POST https://api.floodwaive.de/v1/areas/area_20250519130422/rainfall-events \&lt;br&gt;-H &amp;quot;Authorization: Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&amp;quot; \&lt;br&gt;-H &amp;quot;Content-Type: application/json&amp;quot; \&lt;br&gt;-d '{&lt;br&gt;&amp;quot;name&amp;quot;: &amp;quot;Notebook Test Event - 20250521182410&amp;quot;,&lt;br&gt;&amp;quot;rainfall_values&amp;quot;: [&lt;br&gt;{ &amp;quot;duration&amp;quot;: 300, &amp;quot;intensity&amp;quot;: 5.0 },&lt;br&gt;{ &amp;quot;duration&amp;quot;: 300, &amp;quot;intensity&amp;quot;: 15.0 },&lt;br&gt;{ &amp;quot;duration&amp;quot;: 600, &amp;quot;intensity&amp;quot;: 25.0 },&lt;br&gt;{ &amp;quot;duration&amp;quot;: 2400, &amp;quot;intensity&amp;quot;: 90.0 },&lt;br&gt;{ &amp;quot;duration&amp;quot;: 3600, &amp;quot;intensity&amp;quot;: 0.0 }&lt;br&gt;],&lt;br&gt;&amp;quot;description&amp;quot;: &amp;quot;A 60-minute event created via Jupyter Notebook.&amp;quot;&lt;br&gt;}'</description>
          <description align="center" color="yellow" colored="false" height="153" resized="true" width="181" x="1105" y="418">Create Simulation&lt;br&gt;area_id&lt;br&gt;name&lt;br&gt;rainfall_event_id&lt;br&gt;resolution&lt;br&gt;measures</description>
          <description align="center" color="yellow" colored="false" height="108" resized="false" width="180" x="1011" y="151">Create RainFall event&lt;br&gt;area_id&lt;br&gt;description&lt;br&gt;name&lt;br&gt;rainfall_values</description>
          <description align="center" color="yellow" colored="false" height="108" resized="false" width="180" x="383" y="235">Create Measures&lt;br&gt;area_id&lt;br&gt;geometry&lt;br&gt;name&lt;br&gt;tag</description>
        </process>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="82" name="Generate ga_config" width="90" x="715" y="391">
        <parameter key="script" value="import pandas&#10;import json&#10;&#10;# rm_main is a mandatory function, &#10;# the number of arguments has to be the number of input ports (can be none),&#10;#     or the number of input ports plus one if &quot;use macros&quot; parameter is set&#10;# if you want to use macros, use this instead and check &quot;use macros&quot; parameter:&#10;#def rm_main(data,macros):&#10;def rm_main(data):&#10;    print('Processing optimization request...')&#10;    &#10;    # Get the incoming data from the last row&#10;    incoming_data_str = data.iloc[-1]['value']&#10;    print(f&quot;Incoming data type: {type(incoming_data_str)}&quot;)&#10;    &#10;    # Parse the JSON string&#10;    incoming_data = json.loads(incoming_data_str)&#10;    &#10;    # Extract required values&#10;    optimizer_request_id = incoming_data['optimizerRequestID']&#10;    fitness_score = incoming_data['fitnessScore']&#10;    barriers = incoming_data['barriers']&#10;    &#10;    # Build ga_chromosome_def dynamically from barriers&#10;    ga_chromosome_def = []&#10;    for barrier in barriers:&#10;        chromosome = {&#10;            &quot;name&quot;: barrier['name'],&#10;            &quot;type&quot;: &quot;float&quot;,&#10;            &quot;lower&quot;: barrier['minHeight'],&#10;            &quot;upper&quot;: barrier['maxHeight'],&#10;            &quot;sigma&quot;: 0.1&#10;        }&#10;        ga_chromosome_def.append(chromosome)&#10;    &#10;    # Build the ga_config message&#10;    ga_config = {&#10;        &quot;process_id&quot;: optimizer_request_id,&#10;        &quot;experiment_folder&quot;: &quot;optimizer_runs&quot;,&#10;        &quot;timepoint&quot;: &quot;now&quot;,&#10;        &quot;ga_config.json&quot;: {&#10;            &quot;distance_type&quot;: &quot;l1&quot;,&#10;            &quot;termination_crit&quot;: &quot;fitmin&quot;,&#10;            &quot;termination_args&quot;: fitness_score,&#10;            &quot;pop_num&quot;: 10,&#10;            &quot;crossover_prob&quot;: 0.75,&#10;            &quot;mutation_prob&quot;: 0.5,&#10;            &quot;tournament_size&quot;: 3,&#10;            &quot;ga_chromosome_def&quot;: ga_chromosome_def&#10;        }&#10;    }&#10;    &#10;    # Convert to JSON string for output&#10;    ga_config_json = json.dumps(ga_config, indent=2)&#10;    &#10;    # Print for verification&#10;    print(&quot;Generated ga_config:&quot;)&#10;    print(ga_config_json)&#10;    print(f&quot;\nNumber of barriers processed: {len(barriers)}&quot;)&#10;    for i, barrier in enumerate(barriers, 1):&#10;        print(f&quot;Barrier {i}: {barrier['name']} (height range: {barrier['minHeight']}-{barrier['maxHeight']})&quot;)&#10;    &#10;    # Create output dataframe with the ga_config&#10;    output_data = pandas.DataFrame({&#10;        'config_topic': [ga_config_json]&#10;    })&#10;    &#10;    return output_data"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="82" name="GA" width="90" x="715" y="85">
        <parameter key="script" value="import threading&#10;import random&#10;import time&#10;import math&#10;import csv&#10;import json&#10;import sys&#10;import pickle&#10;import logging&#10;import os&#10;import requests&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;from deap import base&#10;from deap import creator&#10;from deap import tools&#10;from deap import algorithms&#10;&#10;import ga_utils&#10;&#10;experiment_folder = os.path.join('./', 'exp_folder')&#10;logging.basicConfig(&#10;    format='%(message)s',&#10;    filename=os.path.join(experiment_folder, &quot;generations.log&quot;),&#10;    level=logging.INFO&#10;)&#10;transformer = None&#10;&#10;&#10;class Transformer:&#10;&#10;    def __init__(self, ga_params, clf=None, scaler=None):&#10;        self.ga_params = ga_params&#10;&#10;    def mutate(self, population, indpb):&#10;        &quot;&quot;&quot;&#10;        Mutates the values in list individual with probability indpb&#10;        &quot;&quot;&quot;&#10;        for i, param in enumerate(self.ga_params):&#10;            individual = param.mutate(population[i], mu=0, indpb=indpb)&#10;            population[i] = individual&#10;&#10;        return population,&#10;&#10;    def cxUniform(self, ind1, ind2, indpb):&#10;        for _ in range(100):&#10;            c1, c2 = tools.cxUniform(ind1, ind2, indpb)&#10;&#10;        return (c1, c2)&#10;&#10;    def random_params(self):&#10;        draws = []&#10;        for p in self.ga_params:&#10;            draws.append(round(p.randomDraw(), 2))&#10;&#10;        return draws&#10;&#10;    def parse_init_params(self, params_file):&#10;        init_params = []&#10;        with open(params_file) as f_in:&#10;            reader = csv.reader(f_in)&#10;            header = next(reader)&#10;            for row in reader:&#10;                init_params.append(dict(zip(header, row)))&#10;        return init_params&#10;&#10;&#10;def printf(val):&#10;    print(val)&#10;    sys.stdout.flush()&#10;&#10;&#10;def obj_func(x):&#10;    &quot;&quot;&quot;Placeholder objective function&quot;&quot;&quot;&#10;    return 0&#10;&#10;&#10;def num(s):&#10;    &quot;&quot;&quot;Convert string to int or float&quot;&quot;&quot;&#10;    try:&#10;        return int(s)&#10;    except ValueError:&#10;        return float(s)&#10;&#10;&#10;def create_list_of_json_strings(list_of_lists, super_delim=&quot;;&quot;):&#10;    &quot;&quot;&quot;Create string of ; separated jsonified maps&quot;&quot;&quot;&#10;    res = []&#10;    global transformer&#10;    for l in list_of_lists:&#10;        jmap = {}&#10;        for i, p in enumerate(transformer.ga_params):&#10;            jmap[p.name] = l[i]&#10;&#10;        jstring = json.dumps(jmap)&#10;        res.append(jstring)&#10;&#10;    return (super_delim.join(res))&#10;&#10;&#10;def queue_map(obj_func, pops):&#10;    &quot;&quot;&quot;&#10;    Send population to server and receive fitness scores&#10;    &quot;&quot;&quot;&#10;    global proc_id, ga_in_callback&#10;    &#10;    if not pops:&#10;        return []&#10;&#10;    url = &quot;https://server.crexdata.eu/webapi/DEFAULT/api/v1/services/start-simulations/start-simulations&quot;&#10;    &#10;    # Fixed payload structure&#10;    payload = {&#10;        &quot;data&quot;: [&#10;            {&quot;optimizerRequestID&quot;: proc_id},&#10;            {&quot;parameters&quot;: pops}&#10;        ]&#10;    }&#10;    headers = {'Content-type': 'application/json'}&#10;    &#10;    try:&#10;        r = requests.post(url, json=payload, headers=headers)&#10;        print(&quot;Status Code:&quot;, r.status_code)&#10;        print(&quot;Response Body:&quot;, r.text)&#10;    except requests.exceptions.RequestException as e:&#10;        print(f&quot;Request failed: {e}&quot;)&#10;        return []&#10;&#10;    # Receive population fitness scores via callback&#10;    # User should call the callback with ga_in data: {&quot;optimizerRequestID&quot;: proc_id, &quot;results&quot;: [...]}&#10;    if ga_in_callback:&#10;        while True:&#10;            ga_in = ga_in_callback()  # Get ga_in JSON object from user's callback&#10;            if ga_in:&#10;                try:&#10;                    check = ga_in.get(&quot;optimizerRequestID&quot;)&#10;                    &#10;                    if check == proc_id:&#10;                        result = ga_in.get(&quot;results&quot;)&#10;                        if result:&#10;                            result = json.loads(result) if isinstance(result, str) else result&#10;                            print(&quot;Received fitness scores: {}&quot;.format(result))&#10;                            return result&#10;                        else:&#10;                            print(&quot;No results in message&quot;)&#10;                            return []&#10;                except (KeyError, json.JSONDecodeError) as e:&#10;                    print(f&quot;Error processing message: {e}&quot;)&#10;                    print(&quot;Malformed message! Ignoring...&quot;)&#10;                except Exception as e:&#10;                    print(f&quot;Unexpected error: {e}&quot;)&#10;            else:&#10;                time.sleep(0.1)  # Wait for data&#10;&#10;&#10;def make_random_parameters():&#10;    &quot;&quot;&quot;Performs initial random draw on each parameter&quot;&quot;&quot;&#10;    return transformer.random_params()&#10;&#10;&#10;def custom_mutate(individual, indpb):&#10;    &quot;&quot;&quot;Mutates the values in list individual with probability indpb&quot;&quot;&quot;&#10;    return transformer.mutate(individual, indpb)&#10;&#10;&#10;def cxUniform(ind1, ind2, indpb):&#10;    return transformer.cxUniform(ind1, ind2, indpb)&#10;&#10;&#10;def timestamp(scores):&#10;    return str(time.time())&#10;&#10;&#10;def eaSimpleExtended(population, toolbox, cxpb, mutpb, term, ngen, stats=None,&#10;                     halloffame=None, verbose=__debug__, checkpoint=None):&#10;    &quot;&quot;&quot;Extended evolutionary algorithm with checkpointing&quot;&quot;&quot;&#10;    visited_inds = {}&#10;    &#10;    if checkpoint:&#10;        with open(checkpoint, &quot;rb&quot;) as cp_file:&#10;            cp = pickle.load(cp_file)&#10;        population = cp[&quot;population&quot;]&#10;        halloffame = cp[&quot;halloffame&quot;]&#10;        logbook = cp[&quot;logbook&quot;]&#10;        random.setstate(cp[&quot;rndstate&quot;])&#10;    else:&#10;        logbook = tools.Logbook()&#10;        logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])&#10;&#10;    # Evaluate the individuals with an invalid fitness&#10;    invalid_ind = [ind for ind in population &#10;                   if (not ind.fitness.valid) and (str(ind) not in visited_inds)]&#10;    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)&#10;    &#10;    for ind, fit in zip(invalid_ind, fitnesses):&#10;        ind.fitness.values = fit&#10;        visited_inds[str(ind)] = fit&#10;&#10;    if halloffame is not None:&#10;        halloffame.update(population)&#10;    &#10;    record = stats.compile(population) if stats else {}&#10;    logbook.record(gen=0, nevals=len(invalid_ind), **record)&#10;    &#10;    if verbose:&#10;        for p in population:&#10;            logging.debug(&quot;0, {}, {}, {}&quot;.format(0, p, p.fitness))&#10;    &#10;    logging.info(&quot;Initial Generation fitness variance = {}&quot;.format(&#10;        math.pow(float(logbook.select(&quot;std&quot;)[-1]), 2)))&#10;    logging.debug(&quot;Term crit type: {}&quot;.format(type(ngen)))&#10;    &#10;    if term == 'genmax':  # Run for ngens&#10;        logging.debug(&quot;Following normal termination criterion process.&quot;)&#10;        &#10;        for gen in range(1, ngen + 1):&#10;            offspring = toolbox.select(population, len(population))&#10;            offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)&#10;            &#10;            for ind in offspring:&#10;                if str(ind) in visited_inds:&#10;                    ind.fitness.values = visited_inds[str(ind)]&#10;            &#10;            invalid_ind = [ind for ind in offspring &#10;                          if (not ind.fitness.valid) and (str(ind) not in visited_inds)]&#10;            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)&#10;            &#10;            for ind, fit in zip(invalid_ind, fitnesses):&#10;                ind.fitness.values = fit&#10;                visited_inds[str(ind)] = fit&#10;&#10;            if halloffame is not None:&#10;                halloffame.update(offspring)&#10;&#10;            population[:] = offspring&#10;&#10;            record = stats.compile(population) if stats else {}&#10;            logbook.record(gen=gen, nevals=len(invalid_ind), **record)&#10;            &#10;            cp = dict(population=population, generation=gen, halloffame=halloffame,&#10;                     logbook=logbook, rndstate=random.getstate())&#10;            &#10;            with open(checkpoint_file, &quot;wb&quot;) as cp_file:&#10;                pickle.dump(cp, cp_file)&#10;            &#10;            logging.info(&quot;Generation {} Stored at {}&quot;.format(&#10;                gen, time.strftime(&quot;%H:%M:%S&quot;, time.localtime())))&#10;            &#10;            if verbose:&#10;                printf(&quot;Logbookstream: {}\nhalloffame: {}\n&quot;.format(&#10;                    logbook.stream, halloffame))&#10;                for p in population:&#10;                    logging.debug(&quot;0, {}, {}, {}&quot;.format(gen, p, p.fitness))&#10;                for h in halloffame:&#10;                    logging.debug(&quot;-1, {}, {}, {}&quot;.format(gen, h, h.fitness))&#10;    &#10;    else:  # Run while population fitness variance is less than limit&#10;        counter = 0&#10;        gen = 1&#10;        &#10;        while counter &lt; termination_args:&#10;            logging.debug(&quot;Into while, counter = {}&quot;.format(counter))&#10;            &#10;            offspring = toolbox.select(population, len(population))&#10;            offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)&#10;            &#10;            for ind in offspring:&#10;                if str(ind) in visited_inds:&#10;                    ind.fitness.values = visited_inds[str(ind)]&#10;            &#10;            invalid_ind = [ind for ind in offspring &#10;                          if (not ind.fitness.valid) and (str(ind) not in visited_inds)]&#10;            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)&#10;            &#10;            for ind, fit in zip(invalid_ind, fitnesses):&#10;                ind.fitness.values = fit&#10;                visited_inds[str(ind)] = fit&#10;            &#10;            if halloffame is not None:&#10;                halloffame.update(offspring)&#10;&#10;            population[:] = offspring&#10;&#10;            record = stats.compile(population) if stats else {}&#10;            logbook.record(gen=gen, nevals=len(invalid_ind), **record)&#10;            &#10;            cp = dict(population=population, generation=gen, halloffame=halloffame,&#10;                     logbook=logbook, rndstate=random.getstate())&#10;            &#10;            with open(checkpoint_file, &quot;wb&quot;) as cp_file:&#10;                pickle.dump(cp, cp_file)&#10;            &#10;            logging.info(&quot;Generation {} Stored at {}&quot;.format(&#10;                gen, time.strftime(&quot;%H:%M:%S&quot;, time.localtime())))&#10;            &#10;            if verbose:&#10;                printf(&quot;Logbookstream: {}\nhalloffame: {}\n&quot;.format(&#10;                    logbook.stream, halloffame))&#10;                for p in population:&#10;                    logging.debug(&quot;0, {}, {}, {}&quot;.format(gen, p, p.fitness))&#10;                for h in halloffame:&#10;                    logging.debug(&quot;-1, {}, {}, {}&quot;.format(gen, h, h.fitness))&#10;            &#10;            if term == &quot;fitmin&quot;:&#10;                if float(logbook.select(&quot;min&quot;)[-1]) &lt;= ngen:&#10;                    counter += 1&#10;                else:&#10;                    counter = 0&#10;            elif term == &quot;fitvar&quot;:&#10;                if math.pow(float(logbook.select(&quot;std&quot;)[-1]), 2) &lt;= ngen:&#10;                    counter += 1&#10;                else:&#10;                    counter = 0&#10;            elif term == &quot;fitavg&quot;:&#10;                if float(logbook.select(&quot;avg&quot;)[-1]) &lt;= ngen:&#10;                    counter += 1&#10;                else:&#10;                    counter = 0&#10;            else:&#10;                logging.info(&quot;Unknown GA configuration value: '{}'... Exiting&quot;.format(term))&#10;                counter = termination_args&#10;&#10;            logging.debug(&quot;Generation fitness variance = {}, counter is now: {}&quot;.format(&#10;                math.pow(float(logbook.select(&quot;std&quot;)[-1]), 2), counter))&#10;            gen += 1&#10;&#10;    logging.info(&quot;{}\n&quot;.format(logbook.stream))&#10;    return population, logbook&#10;&#10;&#10;def run():&#10;    &quot;&quot;&quot;Main GA execution function&quot;&quot;&quot;&#10;    global ga_config, ga_params, termination_crit, termination_args&#10;    global crossover_prob, mutation_prob, tournament_size, pop_num&#10;    global checkpoint_file, transformer, ga_out&#10;    &#10;    seed = 1234567&#10;&#10;    distance_type_id = ga_config['distance_type']&#10;    logging.info(&quot;Crossover probability: {}, Mutation probability: {}, Tournament size: {}&quot;.format(&#10;        crossover_prob, mutation_prob, tournament_size))&#10;    logging.info(&quot;No. of population: {}, Random seed: {}, GA parameters: {}&quot;.format(&#10;        pop_num, seed, ga_params))&#10;    logging.info(&quot;Distance type - [{}]\t Termination criterion - [{}] - args [{}]\n&quot;.format(&#10;        distance_type_id, termination_crit, termination_args))&#10;    logging.info(&quot;Begin at: {}&quot;.format(time.strftime(&quot;%H:%M:%S&quot;, time.localtime())))&#10;    &#10;    random.seed(seed)&#10;    ga_parameters = ga_utils.create_parameters(ga_params)&#10;    transformer = Transformer(ga_parameters)&#10;&#10;    # DEAP class creators&#10;    creator.create(&quot;FitnessMin&quot;, base.Fitness, weights=(-1.0,))&#10;    creator.create(&quot;Individual&quot;, list, fitness=creator.FitnessMin)&#10;&#10;    # DEAP method definitions&#10;    toolbox = base.Toolbox()&#10;    toolbox.register(&quot;individual&quot;, tools.initIterate, creator.Individual,&#10;                     make_random_parameters)&#10;    toolbox.register(&quot;population&quot;, tools.initRepeat, list, toolbox.individual)&#10;    toolbox.register(&quot;evaluate&quot;, obj_func)&#10;    toolbox.register(&quot;mate&quot;, cxUniform, indpb=crossover_prob)&#10;    toolbox.register(&quot;mutate&quot;, custom_mutate, indpb=mutation_prob)&#10;    toolbox.register(&quot;select&quot;, tools.selTournament, tournsize=tournament_size)&#10;    toolbox.register(&quot;map&quot;, queue_map)&#10;&#10;    pop = toolbox.population(n=pop_num)&#10;&#10;    print(&quot;\n\n\n {} \n\n\n\n&quot;.format(pop))&#10;&#10;    hof = tools.HallOfFame(pop_num)&#10;    stats = tools.Statistics(lambda ind: ind.fitness.values)&#10;    stats.register(&quot;avg&quot;, np.mean)&#10;    stats.register(&quot;std&quot;, np.std)&#10;    stats.register(&quot;min&quot;, np.min)&#10;    stats.register(&quot;max&quot;, np.max)&#10;    stats.register(&quot;ts&quot;, timestamp)&#10;&#10;    start_time = time.time()&#10;    pop, log = eaSimpleExtended(pop, toolbox, cxpb=crossover_prob, mutpb=mutation_prob,&#10;                               term=termination_crit, ngen=num(termination_args),&#10;                               stats=stats, halloffame=hof, verbose=True, checkpoint=None)&#10;    end_time = time.time()&#10;&#10;    fitnesses = [str(p.fitness.values[0]) for p in pop]&#10;    logging.info(&quot;Logbook: \n{}&quot;.format(log))&#10;    logging.info(&quot;\n Hall of Fame: \n&quot;)&#10;    logging.info(&quot;End at: {}&quot;.format(time.strftime(&quot;%H:%M:%S&quot;, time.localtime())))&#10;    &#10;    # Prepare ga_out JSON object&#10;    ga_out = []&#10;    for h in hof:&#10;        logging.debug(&quot;-1, {}, {}, {}&quot;.format(-1, h, h.fitness))&#10;        ga_out.append({&#10;            &quot;process_id&quot;: proc_id,&#10;            &quot;parameters&quot;: list(h),&#10;            &quot;fitness&quot;: h.fitness.values[0]&#10;        })&#10;    &#10;    return ga_out&#10;&#10;&#10;def rm_main(ga_config_input, ga_in_callback_func=None):&#10;    &quot;&quot;&quot;&#10;    Main entry point for the GA optimizer&#10;    &#10;    Args:&#10;        ga_config_input: Either a dict or DataFrame with 'config_topic' column containing JSON string&#10;            Expected structure after parsing:&#10;            {&#10;                &quot;process_id&quot;: str,&#10;                &quot;ga_config.json&quot;: {&#10;                    &quot;termination_crit&quot;: str,&#10;                    &quot;termination_args&quot;: int/float,&#10;                    &quot;crossover_prob&quot;: float,&#10;                    &quot;mutation_prob&quot;: float,&#10;                    &quot;tournament_size&quot;: int,&#10;                    &quot;pop_num&quot;: int,&#10;                    &quot;distance_type&quot;: str&#10;                },&#10;                &quot;ga_chromosome_def&quot;: list&#10;            }&#10;        ga_in_callback_func (callable): Optional callback function that returns ga_in JSON object:&#10;            {&#10;                &quot;optimizerRequestID&quot;: str,&#10;                &quot;results&quot;: list of fitness scores&#10;            }&#10;    &#10;    Returns:&#10;        list: ga_out - List of best solutions with structure:&#10;            [&#10;                {&#10;                    &quot;process_id&quot;: str,&#10;                    &quot;parameters&quot;: list,&#10;                    &quot;fitness&quot;: float&#10;                },&#10;                ...&#10;            ]&#10;    &quot;&quot;&quot;&#10;    global ga_config, ga_params, termination_crit, termination_args&#10;    global crossover_prob, mutation_prob, tournament_size, pop_num&#10;    global checkpoint_file, proc_id, ga_in_callback&#10;&#10;    ga_in_callback = ga_in_callback_func&#10;&#10;    try:&#10;        # Handle DataFrame input&#10;        if isinstance(ga_config_input, pd.DataFrame):&#10;            print(&quot;Input is DataFrame, extracting config_topic column&quot;)&#10;            if 'config_topic' in ga_config_input.columns:&#10;                config_json_str = ga_config_input['config_topic'].iloc[0]&#10;                ga_config_input = json.loads(config_json_str)&#10;            else:&#10;                raise ValueError(&quot;DataFrame must have 'config_topic' column&quot;)&#10;        &#10;        print(&quot;Initiating simulations with configurations: {}&quot;.format(ga_config_input))&#10;        print(&quot;Available keys in ga_config_input: {}&quot;.format(list(ga_config_input.keys())))&#10;        &#10;        proc_id = ga_config_input['process_id']&#10;        ga_config = ga_config_input['ga_config.json']&#10;        print(&quot;Loaded configuration: {}&quot;.format(ga_config))&#10;        &#10;        termination_crit = ga_config['termination_crit']&#10;        termination_args = ga_config['termination_args']&#10;        crossover_prob = float(ga_config['crossover_prob'])&#10;        mutation_prob = float(ga_config['mutation_prob'])&#10;        tournament_size = int(ga_config['tournament_size'])&#10;        pop_num = int(ga_config['pop_num'])&#10;        checkpoint_file = os.path.join(experiment_folder, &quot;ga_checkpoint.pkl&quot;)&#10;        &#10;        # Try different possible keys for chromosome definition&#10;        if 'ga_chromosome_def' in ga_config_input:&#10;            ga_params = ga_config_input['ga_chromosome_def']&#10;        elif 'chromosome_def' in ga_config_input:&#10;            ga_params = ga_config_input['chromosome_def']&#10;        elif 'ga_chromosome_def' in ga_config:&#10;            ga_params = ga_config['ga_chromosome_def']&#10;        elif 'chromosome_def' in ga_config:&#10;            ga_params = ga_config['chromosome_def']&#10;        else:&#10;            raise KeyError(&quot;Could not find chromosome definition. Looked for: 'ga_chromosome_def' or 'chromosome_def' in both ga_config_input and ga_config.json&quot;)&#10;        &#10;        print(&quot;Loaded chromosome definitions: {}&quot;.format(ga_params))&#10;        &#10;        ga_out = run()&#10;        print(&quot;\nOptimization Completed!\n&quot;)&#10;        return ga_out&#10;&#10;    except KeyError as e:&#10;        print(f&quot;KeyError: {e}&quot;)&#10;        print(&quot;Malformed configuration! Check your ga_config structure.&quot;)&#10;        raise&#10;    except Exception as e:&#10;        print(f&quot;Unexpected error: {e}&quot;)&#10;        raise&#10;&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    # Example usage&#10;    example_ga_config = {&#10;        &quot;process_id&quot;: &quot;test_process_001&quot;,&#10;        &quot;ga_config.json&quot;: {&#10;            &quot;termination_crit&quot;: &quot;genmax&quot;,&#10;            &quot;termination_args&quot;: 10,&#10;            &quot;crossover_prob&quot;: 0.7,&#10;            &quot;mutation_prob&quot;: 0.2,&#10;            &quot;tournament_size&quot;: 3,&#10;            &quot;pop_num&quot;: 20,&#10;            &quot;distance_type&quot;: &quot;euclidean&quot;&#10;        },&#10;        &quot;ga_chromosome_def&quot;: [&#10;            {&quot;name&quot;: &quot;param1&quot;, &quot;type&quot;: &quot;float&quot;, &quot;min&quot;: 0, &quot;max&quot;: 1},&#10;            {&quot;name&quot;: &quot;param2&quot;, &quot;type&quot;: &quot;float&quot;, &quot;min&quot;: 0, &quot;max&quot;: 10}&#10;        ]&#10;    }&#10;    &#10;    # Define a callback function to provide ga_in data&#10;    def get_ga_in():&#10;        # This should return fitness results when available&#10;        return {&#10;            &quot;optimizerRequestID&quot;: &quot;test_process_001&quot;,&#10;            &quot;results&quot;: [0.5, 0.3, 0.8]  # Example fitness scores&#10;        }&#10;    &#10;    # Run the optimizer&#10;    results = rm_main(example_ga_config, get_ga_in)&#10;    print(&quot;Final results (ga_out):&quot;)&#10;    print(json.dumps(results, indent=2))"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <connect from_op="Retrieve kafka-no-auth" from_port="output" to_op="Read Kafka Topic" to_port="connection"/>
      <connect from_op="Retrieve Optimizer-Input-Kafka" from_port="output" to_port="result 1"/>
      <connect from_op="Retrieve kafka-no-auth (2)" from_port="output" to_op="Read Kafka Topic (2)" to_port="connection"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <description align="left" color="yellow" colored="false" height="373" resized="true" width="648" x="100" y="236">This is a Webservice receiving Optimizer Parameters&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;Example (10 simulations with 3 barriers). For each barrier the provided values are the height of the barrier:&lt;br&gt;&lt;br&gt;[[4.83, 0.38, 1.32], [4.80, 0.37, 2.32], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23], [4.82, 0.37, 9.23]]&lt;br&gt;&lt;br&gt;Each Barrier needs to created using the Floodwaive API and then a simulation containing these needs to be started.&lt;br&gt;Then the Simulation ID needs to be monitored and as soon as the result is available. we need to provide the result to the optimizer in a Kafka topic in the format&lt;br&gt;&lt;br&gt;[[28], [48], [52], [94], [94], [474], [59], [3245], [7651], [6295]]&lt;br&gt;&lt;br&gt;&lt;br&gt;Random Rainfall event ID:&lt;br&gt;rainfall-event-8a1c5705-9cf6-4d0b-9da8-553fab3bafc0</description>
    </process>
  </operator>
</process>
