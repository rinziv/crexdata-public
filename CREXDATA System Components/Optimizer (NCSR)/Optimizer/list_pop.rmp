<?xml version="1.0" encoding="UTF-8"?><process version="10.5.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="10.5.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="pops" width="90" x="45" y="187">
        <parameter key="repository_entry" value="//ncsr-optimizer-integration/NCSR-Optimizer/OptimizerID + pops incomming_data"/>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="103" name="Execute Python" width="90" x="179" y="136">
        <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;import ast&#10;&#10;def rm_main(data):&#10;    &quot;&quot;&quot;&#10;    Main function for RapidMiner Execute Python operator.&#10;    &#10;    Args:&#10;        data: Input data containing optimizer results with structure:&#10;              {&quot;data&quot;: [{&quot;optimizerRequestID&quot;: &quot;...&quot;, &quot;parameters&quot;: &quot;[[...], ...]&quot;}]}&#10;    &#10;    Returns:&#10;        tuple: (df_params, df_opid) - Parameters DataFrame and Optimizer ID DataFrame&#10;    &quot;&quot;&quot;&#10;    # Parse the input data (barrier configurations)&#10;    if isinstance(data, pd.DataFrame):&#10;        if len(data) == 0:&#10;            raise ValueError(&quot;Input DataFrame is empty&quot;)&#10;        &#10;        # Check if there's a 'value' column (Kafka message format)&#10;        if 'value' in data.columns:&#10;            json_str = data.iloc[-1]['value']&#10;            input_data = json.loads(json_str)&#10;        else:&#10;            # Try to parse the first column&#10;            json_str = data.iloc[0, 0]&#10;            try:&#10;                input_data = json.loads(json_str)&#10;            except (json.JSONDecodeError, TypeError):&#10;                # Last resort: convert row to dict&#10;                input_data = data.iloc[-1].to_dict()&#10;    else:&#10;        # If input is already a dict (like from Kafka)&#10;        if isinstance(data, dict) and 'value' in data:&#10;            # Parse the JSON string in the 'value' field&#10;            input_data = json.loads(data['value'])&#10;        else:&#10;            input_data = data&#10;    &#10;    print(&quot;Full input_data:&quot;, input_data)&#10;    &#10;    # CORRECTED: Handle the actual data structure&#10;    # Your data: {&quot;data&quot;: [{&quot;optimizerRequestID&quot;: &quot;...&quot;, &quot;parameters&quot;: &quot;...&quot;}]}&#10;    if 'data' in input_data and len(input_data['data']) &gt; 0:&#10;        optimizer_data = input_data['data'][0]  # Get first element from 'data' array&#10;        &#10;        optimizer_request_id = optimizer_data['optimizerRequestID']&#10;        parameters_raw = optimizer_data['parameters']&#10;        &#10;        print(f&quot;Optimizer ID: {optimizer_request_id}&quot;)&#10;        print(f&quot;Parameters (raw): {parameters_raw}&quot;)&#10;        print(f&quot;Parameters type: {type(parameters_raw)}&quot;)&#10;        &#10;        # Handle parameters - could be string or list&#10;        if isinstance(parameters_raw, str):&#10;            # Parse string representation back to list&#10;            try:&#10;                parameters = ast.literal_eval(parameters_raw)&#10;                print(f&quot;Parsed parameters: {parameters}&quot;)&#10;            except Exception as e:&#10;                print(f&quot;Error parsing parameters: {e}&quot;)&#10;                try:&#10;                    parameters = json.loads(parameters_raw)&#10;                except:&#10;                    parameters = []  # Fallback empty list&#10;        else:&#10;            # Already a list&#10;            parameters = parameters_raw&#10;        &#10;        # Create DataFrames&#10;        df_opid = pd.DataFrame([optimizer_request_id])&#10;        df_params = pd.DataFrame(parameters)&#10;        &#10;        print(f&quot;df_opid: {df_opid}&quot;)&#10;        print(f&quot;df_params shape: {df_params.shape}&quot;)&#10;        print(f&quot;df_params:\n{df_params}&quot;)&#10;        &#10;        return df_params, df_opid&#10;    &#10;    # FALLBACK: Try the old format for compatibility&#10;    elif isinstance(input_data, list) and len(input_data) &gt;= 2:&#10;        print(&quot;Using old format compatibility&quot;)&#10;        df_opid = pd.DataFrame([input_data[0]['optimizerRequestID']])&#10;        &#10;        # FIXED: Parse parameters string&#10;        parameters_raw = input_data[1]['parameters']&#10;        if isinstance(parameters_raw, str):&#10;            try:&#10;                parameters = ast.literal_eval(parameters_raw)&#10;            except:&#10;                parameters = json.loads(parameters_raw)&#10;        else:&#10;            parameters = parameters_raw&#10;            &#10;        df_params = pd.DataFrame(parameters)&#10;        return df_params, df_opid&#10;    &#10;    else:&#10;        print(&quot;Unexpected data structure&quot;)&#10;        print(f&quot;input_data type: {type(input_data)}&quot;)&#10;        print(f&quot;input_data keys: {input_data.keys() if isinstance(input_data, dict) else 'not a dict'}&quot;)&#10;        &#10;        # Fallback&#10;        df_opid = pd.DataFrame(['unknown'])&#10;        df_params = pd.DataFrame([[4.83, 0.38, 1.32]])&#10;        return df_params, df_opid"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve rainfall-event-creation" width="90" x="648" y="646">
        <parameter key="repository_entry" value="rainfall-event-creation"/>
      </operator>
      <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve polling-operator-output" width="90" x="112" y="595">
        <parameter key="repository_entry" value="polling-operator-output"/>
      </operator>
      <operator activated="false" class="append" compatibility="10.5.000" expanded="true" height="82" name="Append (2)" width="90" x="246" y="595">
        <parameter key="data_management" value="auto"/>
        <parameter key="merge_type" value="all"/>
      </operator>
      <operator activated="true" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve Optimizer-Input-Kafka" width="90" x="45" y="340">
        <parameter key="repository_entry" value="Optimizer-Input-Kafka"/>
      </operator>
      <operator activated="true" class="multiply" compatibility="10.5.000" expanded="true" height="103" name="Multiply (2)" width="90" x="179" y="340"/>
      <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="103" name="Create Rainfall event (2)" width="90" x="313" y="391">
        <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(data):&#10;    &quot;&quot;&quot;&#10;    Main function for RapidMiner Execute Python operator.&#10;    &#10;    Args:&#10;        data: Input data (can be a pandas DataFrame or dict)&#10;    &#10;    Returns:&#10;        pandas.DataFrame: DataFrame containing the rainfall_event_id&#10;    &quot;&quot;&quot;&#10;    # If data is a DataFrame, extract the actual data&#10;    if isinstance(data, pd.DataFrame):&#10;        if len(data) == 0:&#10;            raise ValueError(&quot;Input DataFrame is empty&quot;)&#10;        &#10;        # Check if there's a 'value' column (Kafka message format)&#10;        if 'value' in data.columns:&#10;            json_str = data.iloc[-1]['value']&#10;            input_data = json.loads(json_str)&#10;        else:&#10;            # Try to parse the first column&#10;            json_str = data.iloc[0, 0]&#10;            try:&#10;                input_data = json.loads(json_str)&#10;            except (json.JSONDecodeError, TypeError):&#10;                # Last resort: convert row to dict&#10;                input_data = data.iloc[0].to_dict()&#10;    else:&#10;        # If input is already a dict (like from Kafka)&#10;        if isinstance(data, dict) and 'value' in data:&#10;            # Parse the JSON string in the 'value' field&#10;            input_data = json.loads(data['value'])&#10;        else:&#10;            input_data = data&#10;    &#10;    result_df = send_rainfall_event(input_data)&#10;    return result_df&#10;&#10;def send_rainfall_event(input_data):&#10;    &quot;&quot;&quot;&#10;    Send rainfall event data to the API and return the rainfall_event_id.&#10;    &#10;    Args:&#10;        input_data: Dictionary containing the rainfall event data&#10;    &#10;    Returns:&#10;        pandas.DataFrame: DataFrame with rainfall_event_id and other metadata&#10;    &quot;&quot;&quot;&#10;    # Configuration&#10;    API_BASE_URL = &quot;https://api.floodwaive.de/v1&quot;&#10;    &#10;    # Area ID mapping&#10;    AREA_IDS = {&#10;        &quot;Dortmund&quot;: &quot;20250519130422&quot;,&#10;        &quot;Innsbruck&quot;: &quot;20250913133225&quot;&#10;    }&#10;    &#10;    # Get the area from the input data and map to area ID&#10;    area_name = input_data.get(&quot;area&quot;)&#10;    &#10;    if area_name is None:&#10;        raise ValueError(f&quot;'area' field not found in input data. Available keys: {list(input_data.keys())}&quot;)&#10;    &#10;    AREA_ID = AREA_IDS.get(area_name)&#10;    &#10;    if AREA_ID is None:&#10;        raise ValueError(f&quot;Unknown area: {area_name}. Supported areas: {list(AREA_IDS.keys())}&quot;)&#10;    &#10;    print(f&quot;Detected Area: {area_name}&quot;)&#10;    print(f&quot;Using Area ID: {AREA_ID}&quot;)&#10;    &#10;    # Build the API endpoint&#10;    API_TOKEN = 'fw_ba692f29ca5d40cdbae6c6fd75179a3a'&#10;    endpoint = f&quot;{API_BASE_URL}/areas/area_{AREA_ID}/rainfall-events&quot;&#10;    &#10;    # Transform the rainfall intervals to match the API format&#10;    rainfall_values = [&#10;        {&#10;            &quot;duration&quot;: interval[&quot;duration&quot;],&#10;            &quot;intensity&quot;: interval[&quot;intensity&quot;]&#10;        }&#10;        for interval in input_data[&quot;rainfallEvent&quot;][&quot;rainfallIntervals&quot;]&#10;    ]&#10;    &#10;    # Prepare the request body&#10;    request_body = {&#10;        &quot;name&quot;: input_data[&quot;rainfallEvent&quot;][&quot;name&quot;],&#10;        &quot;rainfall_values&quot;: rainfall_values,&#10;        &quot;description&quot;: &quot;Test Description&quot;&#10;    }&#10;        # Prepare headers with authentication&#10;    headers = {&#10;        &quot;Content-Type&quot;: &quot;application/json&quot;&#10;        &#10;    }&#10;    headers[&quot;Authorization&quot;] = f&quot;Bearer {API_TOKEN}&quot;&#10;    # Print the request details&#10;    print(&quot;=&quot; * 60)&#10;    print(&quot;API Request Details&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    print(f&quot;Endpoint: {endpoint}&quot;)&#10;    print(f&quot;\nRequest Body:&quot;)&#10;    print(json.dumps(request_body, indent=2))&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    # Send the POST request&#10;    try:&#10;        response = requests.post(&#10;            endpoint,&#10;            json=request_body,&#10;            headers = headers&#10;        )&#10;        &#10;        # Print response details&#10;        print(f&quot;\nResponse Status Code: {response.status_code}&quot;)&#10;        &#10;        # Check if request was successful&#10;        if response.status_code in [200, 201]:&#10;            print(&quot;✓ Request successful!&quot;)&#10;            &#10;            # Parse the response JSON&#10;            response_data = response.json()&#10;            &#10;            # Create DataFrame with key information&#10;            result_df = pd.DataFrame([{&#10;                &quot;rainfall_event_id&quot;: response_data.get(&quot;rainfall_event_id&quot;),&#10;                &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: response_data.get(&quot;area_id&quot;),&#10;                &quot;created_at&quot;: response_data.get(&quot;created_at&quot;),&#10;                &quot;status&quot;: &quot;success&quot;,&#10;                &quot;status_code&quot;: response.status_code&#10;            }])&#10;            &#10;            print(f&quot;\nRainfall Event ID: {response_data.get('rainfall_event_id')}&quot;)&#10;            &#10;            return result_df&#10;        else:&#10;            print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;            &#10;            # Return error DataFrame&#10;            error_df = pd.DataFrame([{&#10;                &quot;rainfall_event_id&quot;: None,&#10;                &quot;name&quot;: request_body.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: f&quot;area_{AREA_ID}&quot;,&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;failed&quot;,&#10;                &quot;status_code&quot;: response.status_code,&#10;                &quot;error_message&quot;: response.text&#10;            }])&#10;            &#10;            return error_df&#10;            &#10;    except requests.exceptions.RequestException as e:&#10;        print(f&quot;✗ Error sending request: {e}&quot;)&#10;        &#10;        # Return error DataFrame&#10;        error_df = pd.DataFrame([{&#10;            &quot;rainfall_event_id&quot;: None,&#10;            &quot;name&quot;: request_body.get(&quot;name&quot;),&#10;            &quot;area_id&quot;: f&quot;area_{AREA_ID}&quot;,&#10;            &quot;created_at&quot;: None,&#10;            &quot;status&quot;: &quot;error&quot;,&#10;            &quot;status_code&quot;: None,&#10;            &quot;error_message&quot;: str(e)&#10;        }])&#10;        &#10;        return error_df&#10;"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <operator activated="false" class="loop_examples" compatibility="10.5.000" expanded="true" height="145" name="Loop Examples" width="90" x="782" y="493">
        <parameter key="iteration_macro" value="example"/>
        <process expanded="true">
          <operator activated="true" class="multiply" compatibility="10.5.000" expanded="true" height="124" name="Multiply" width="90" x="112" y="187"/>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="145" name="Create Measure" width="90" x="246" y="34">
            <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(elevation_change, op_id, kafka_input, macros):&#10;    row_index = int(macros.get('example'))&#10;    &#10;    print(f&quot;================{row_index-1}=====================&quot;)&#10;    print(&quot;OptimizerID&quot;, op_id.iloc[0]['att0'])&#10;    print(elevation_change.iloc[row_index-1])&#10;    &#10;    # Parse the kafka_input JSON to extract required data&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;    print(kafka_data)&#10;    &#10;    # Extract area_id from the area field and map to correct format&#10;    area_name = kafka_data['area']&#10;    print(area_name)&#10;    &#10;    # Map city names to their corresponding area IDs&#10;    area_mapping = {&#10;        'Dortmund': 'area_20250519130422',&#10;        'Innsbruck': 'area_20250913133225'&#10;    }&#10;    &#10;    area_id = area_mapping.get(area_name, f'area_{area_name}')  # fallback to area_{name} if not found&#10;&#10;    # Get elevation change value for the current row&#10;    current_elevation_change = elevation_change.iloc[row_index-1]&#10;    &#10;    # Extract barriers data which contains tag and geometry&#10;    barriers = kafka_data.get('barriers', [])&#10;    results = []&#10;    &#10;    # Process each barrier and make API calls&#10;    for i, barrier in enumerate(barriers):&#10;        # Extract required fields&#10;        tag = barrier['tag']&#10;        geometry = barrier['geometry']&#10;        barrier_name = barrier['name']&#10;        &#10;        # Get elevation change value - use different value for each barrier&#10;        if hasattr(current_elevation_change, 'iloc') and len(current_elevation_change) &gt; i:&#10;            elevation_value = current_elevation_change.iloc[i]&#10;        elif hasattr(current_elevation_change, 'iloc'):&#10;            elevation_value = current_elevation_change.iloc[0]  # fallback to first if not enough values&#10;        else:&#10;            elevation_value = current_elevation_change&#10;        &#10;        # Prepare the API payload&#10;        payload = {&#10;            &quot;name&quot;: f&quot;RapidMiner Workflow {tag} - {barrier_name}&quot;,&#10;            &quot;tag&quot;: tag,&#10;            &quot;geometry&quot;: geometry,&#10;            &quot;elevation_change&quot;: float(elevation_value),&#10;            &quot;description&quot;: f&quot;A {elevation_value}m high flood {tag.lower()} created via RapidMiner.&quot;&#10;        }&#10;        &#10;        # Make the API call&#10;        try:&#10;            url = f&quot;https://api.floodwaive.de/v1/areas/{area_id}/measures&quot;&#10;            headers = {&#10;                &quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;,&#10;                &quot;Content-Type&quot;: &quot;application/json&quot;&#10;            }&#10;            &#10;            response = requests.post(url, headers=headers, json=payload)&#10;            &#10;            print(f&quot;API call for {barrier_name}:&quot;)&#10;            print(f&quot;Status Code: {response.status_code}&quot;)&#10;            &#10;            if response.status_code == 200:&#10;                print(f&quot;Response: {response.text}&quot;)&#10;                &#10;                response_data = response.json()&#10;                &#10;                # Add to results&#10;                results.append({&#10;                    &quot;measure_id&quot;: response_data.get(&quot;measure_id&quot;),&#10;                    &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                    &quot;area_id&quot;: response_data.get(&quot;area_id&quot;),&#10;                    &quot;tag&quot;: response_data.get(&quot;tag&quot;),&#10;                    &quot;elevation_change&quot;: response_data.get(&quot;elevation_change&quot;),&#10;                    &quot;created_at&quot;: response_data.get(&quot;created_at&quot;),&#10;                    &quot;status&quot;: &quot;success&quot;,&#10;                    &quot;status_code&quot;: response.status_code&#10;                })&#10;                &#10;                print(f&quot;Measure ID: {response_data.get('measure_id')}&quot;)&#10;                &#10;            else:&#10;                print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;                print(f&quot;Response: {response.text}&quot;)&#10;                &#10;                # Add error to results&#10;                results.append({&#10;                    &quot;measure_id&quot;: None,&#10;                    &quot;name&quot;: payload.get(&quot;name&quot;),&#10;                    &quot;area_id&quot;: area_id,&#10;                    &quot;tag&quot;: payload.get(&quot;tag&quot;),&#10;                    &quot;elevation_change&quot;: payload.get(&quot;elevation_change&quot;),&#10;                    &quot;created_at&quot;: None,&#10;                    &quot;status&quot;: &quot;failed&quot;,&#10;                    &quot;status_code&quot;: response.status_code,&#10;                    &quot;error_message&quot;: response.text&#10;                })&#10;                &#10;            print(&quot;=====================================&quot;)&#10;            &#10;        except requests.exceptions.RequestException as e:&#10;            print(f&quot;✗ Error sending request: {e}&quot;)&#10;            print(&quot;=====================================&quot;)&#10;            &#10;            # Add error to results&#10;            results.append({&#10;                &quot;measure_id&quot;: None,&#10;                &quot;name&quot;: payload.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;tag&quot;: payload.get(&quot;tag&quot;),&#10;                &quot;elevation_change&quot;: payload.get(&quot;elevation_change&quot;),&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;error&quot;,&#10;                &quot;status_code&quot;: None,&#10;                &quot;error_message&quot;: str(e)&#10;            })&#10;        &#10;        except Exception as e:&#10;            print(f&quot;✗ Unexpected error for {barrier_name}: {e}&quot;)&#10;            print(&quot;=====================================&quot;)&#10;            &#10;            # Add error to results&#10;            results.append({&#10;                &quot;measure_id&quot;: None,&#10;                &quot;name&quot;: payload.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;tag&quot;: payload.get(&quot;tag&quot;),&#10;                &quot;elevation_change&quot;: payload.get(&quot;elevation_change&quot;),&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;error&quot;,&#10;                &quot;status_code&quot;: None,&#10;                &quot;error_message&quot;: str(e)&#10;            })&#10;    &#10;    # Create DataFrame with all results&#10;    result_df = pd.DataFrame(results)&#10;    &#10;    print(&quot;\n&quot; + &quot;=&quot; * 60)&#10;    print(f&quot;Summary: Created {len([r for r in results if r['status'] == 'success'])}/{len(barriers)} barriers successfully&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    return result_df"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="true"/>
            <description align="center" color="transparent" colored="false" width="126">Will be user later&lt;br/&gt;&lt;br/&gt;</description>
          </operator>
          <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve measures-barriers-creation" width="90" x="45" y="646">
            <parameter key="repository_entry" value="measures-barriers-creation"/>
          </operator>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="145" name="CreateSimulation" width="90" x="380" y="391">
            <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(measures, kafka_input, rainfall_event):&#10;    &quot;&quot;&quot;&#10;    Alternative version that returns a DataFrame with detailed simulation info&#10;    instead of just the simulation_id&#10;    &quot;&quot;&quot;&#10;    &#10;    print(measures)&#10;    rainfall_event_id = rainfall_event.iloc[0]['rainfall_event_id']&#10;    print(rainfall_event_id)&#10;    &#10;    # Parse the kafka_input JSON to extract required data&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;    print(kafka_data)&#10;    &#10;    # Extract area_id from the area field and map to correct format&#10;    area_name = kafka_data['area']&#10;    &#10;    # Map city names to their corresponding area IDs&#10;    area_mapping = {&#10;        'Dortmund': 'area_20250519130422',&#10;        'Innsbruck': 'area_20250913133225'&#10;    }&#10;    &#10;    area_id = area_mapping.get(area_name, f'area_{area_name}')&#10;    &#10;    # Extract rainfall event name from kafka_data&#10;    rainfall_event_name = kafka_data.get('rainfallEvent', {}).get('name', 'unknown_event')&#10;    &#10;    # Get list of measure IDs from the measures DataFrame&#10;    measure_ids = measures['measure_id'].tolist()&#10;    &#10;    # Prepare the API payload for simulation&#10;    simulation_name = f&quot;Optimizer {rainfall_event_name} Simulation&quot;&#10;    &#10;    payload = {&#10;        &quot;name&quot;: simulation_name,&#10;        &quot;model_id&quot;: &quot;deepwaive-4.0-pre-latest&quot;,&#10;        &quot;resolution&quot;: 4,&#10;        &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;        &quot;measures&quot;: measure_ids&#10;    }&#10;    &#10;    print(f&quot;Creating simulation with {len(measure_ids)} measures:&quot;)&#10;    print(f&quot;Area ID: {area_id}&quot;)&#10;    print(f&quot;Simulation Name: {simulation_name}&quot;)&#10;    print(f&quot;Rainfall Event ID: {rainfall_event_id}&quot;)&#10;    print(f&quot;Measures: {measure_ids}&quot;)&#10;    &#10;    # Make the API call to create simulation&#10;    try:&#10;        url = f&quot;https://api.floodwaive.de/v1/areas/{area_id}/simulations&quot;&#10;        headers = {&#10;            &quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;,&#10;            &quot;Content-Type&quot;: &quot;application/json&quot;&#10;        }&#10;        &#10;        response = requests.post(url, headers=headers, json=payload)&#10;        &#10;        print(f&quot;\nAPI call to create simulation:&quot;)&#10;        print(f&quot;URL: {url}&quot;)&#10;        print(f&quot;Status Code: {response.status_code}&quot;)&#10;        &#10;        if response.status_code in [200, 201]:  # Success codes&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            &#10;            response_data = response.json()&#10;            simulation_id = response_data.get(&quot;simulation_id&quot;) or response_data.get(&quot;id&quot;)&#10;            &#10;            print(f&quot;✓ Simulation created successfully!&quot;)&#10;            print(f&quot;Simulation ID: {simulation_id}&quot;)&#10;            &#10;            # Create result dictionary&#10;            result = {&#10;                &quot;simulation_id&quot;: simulation_id,&#10;                &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;                &quot;measures_count&quot;: len(measure_ids),&#10;                &quot;status&quot;: &quot;success&quot;,&#10;                &quot;status_code&quot;: response.status_code,&#10;                &quot;created_at&quot;: response_data.get(&quot;created_at&quot;)&#10;            }&#10;            &#10;        else:&#10;            print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            &#10;            # Create error result&#10;            result = {&#10;                &quot;simulation_id&quot;: None,&#10;                &quot;name&quot;: simulation_name,&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;                &quot;measures_count&quot;: len(measure_ids),&#10;                &quot;status&quot;: &quot;failed&quot;,&#10;                &quot;status_code&quot;: response.status_code,&#10;                &quot;error_message&quot;: response.text,&#10;                &quot;created_at&quot;: None&#10;            }&#10;            &#10;    except Exception as e:&#10;        print(f&quot;✗ Error: {e}&quot;)&#10;        &#10;        # Create error result&#10;        result = {&#10;            &quot;simulation_id&quot;: None,&#10;            &quot;name&quot;: simulation_name,&#10;            &quot;area_id&quot;: area_id,&#10;            &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;            &quot;measures_count&quot;: len(measure_ids),&#10;            &quot;status&quot;: &quot;error&quot;,&#10;            &quot;status_code&quot;: None,&#10;            &quot;error_message&quot;: str(e),&#10;            &quot;created_at&quot;: None&#10;        }&#10;    &#10;    # Return DataFrame with simulation details&#10;    result_df = pd.DataFrame([result])&#10;    &#10;    print(f&quot;\nSummary:&quot;)&#10;    print(f&quot;Status: {result['status']}&quot;)&#10;    print(f&quot;Simulation ID: {result.get('simulation_id')}&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    return result_df"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="103" name="Polling Operator" width="90" x="514" y="34">
            <parameter key="script" value="import pandas&#10;import requests&#10;import time&#10;import json&#10;&#10;# Configuration&#10;API_TOKEN = &quot;fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;&#10;&#10;# Polling config - SHORTER INTERVALS&#10;INITIAL_INTERVAL = 0.5  # Start with 0.5 seconds instead of 2&#10;MAX_INTERVAL = 10       # Max 10 seconds instead of 30&#10;BACKOFF_MULTIPLIER = 1.2  # Slower backoff (1.2 instead of 1.5)&#10;&#10;def poll_simulation(simulation_id):&#10;    &quot;&quot;&quot;Poll simulation endpoint until COMPLETE status&quot;&quot;&quot;&#10;    api_url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/progress&quot;&#10;    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}&#10;    &#10;    interval = INITIAL_INTERVAL&#10;    last_status = None&#10;    &#10;    while True:&#10;        try:&#10;            response = requests.get(api_url, headers=headers, timeout=10)&#10;            response.raise_for_status()&#10;            data = response.json()&#10;            &#10;            status = data.get(&quot;status_v5&quot;, &quot;UNKNOWN&quot;)&#10;            print(f&quot;[{time.strftime('%H:%M:%S')}] Status: {status}&quot;)&#10;            &#10;            if status == &quot;COMPLETE&quot;:&#10;                print(&quot;✓ Simulation complete!&quot;)&#10;                return data&#10;            &#10;            # Reset interval if status changed&#10;            if status != last_status:&#10;                interval = INITIAL_INTERVAL&#10;                last_status = status&#10;            else:&#10;                interval = min(interval * BACKOFF_MULTIPLIER, MAX_INTERVAL)&#10;            &#10;            print(f&quot;Waiting {interval:.1f}s...&quot;)&#10;            time.sleep(interval)&#10;            &#10;        except requests.RequestException as e:&#10;            print(f&quot;Error: {e}. Retrying in 2s...&quot;)  # Shorter retry interval too&#10;            time.sleep(2)&#10;&#10;def rm_main(data):&#10;    &quot;&quot;&quot;&#10;    RapidMiner main function&#10;    Input: DataFrame with 'simulation_id' column&#10;    Output: Original data + Results DataFrame with simulation_id&#10;    &quot;&quot;&quot;&#10;    print('Starting simulation polling...')&#10;    &#10;    # Get simulation ID from input data&#10;    if 'simulation_id' not in data.columns:&#10;        raise ValueError(&quot;Input data must contain 'simulation_id' column&quot;)&#10;    &#10;    simulation_id = data['simulation_id'].iloc[0]&#10;    print(f&quot;Monitoring simulation: {simulation_id}&quot;)&#10;    &#10;    # Poll until complete&#10;    completion_data = poll_simulation(simulation_id)&#10;    &#10;    # Return only simulation_id as DataFrame&#10;    results = pandas.DataFrame([{&quot;simulation_id&quot;: simulation_id}])&#10;    &#10;    return results&#10;&#10;&#10;# Alternative version with even more aggressive polling&#10;def rm_main_fast(data):&#10;    &quot;&quot;&quot;&#10;    Very fast polling version&#10;    &quot;&quot;&quot;&#10;    print('Starting FAST simulation polling...')&#10;    &#10;    simulation_id = data['simulation_id'].iloc[0]&#10;    print(f&quot;Monitoring simulation: {simulation_id}&quot;)&#10;    &#10;    api_url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/progress&quot;&#10;    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}&#10;    &#10;    # Very aggressive polling - check every 0.2 seconds initially&#10;    interval = 0.2&#10;    max_interval = 5&#10;    &#10;    while True:&#10;        try:&#10;            response = requests.get(api_url, headers=headers, timeout=5)&#10;            response.raise_for_status()&#10;            data_response = response.json()&#10;            &#10;            status = data_response.get(&quot;status_v5&quot;, &quot;UNKNOWN&quot;)&#10;            print(f&quot;[{time.strftime('%H:%M:%S.%f')[:-3]}] Status: {status}&quot;)&#10;            &#10;            if status == &quot;COMPLETE&quot;:&#10;                print(&quot;✓ Simulation complete!&quot;)&#10;                break&#10;            &#10;            # Gradual backoff but stay aggressive&#10;            time.sleep(interval)&#10;            interval = min(interval * 1.1, max_interval)&#10;            &#10;        except requests.RequestException as e:&#10;            print(f&quot;Error: {e}. Retrying in 1s...&quot;)&#10;            time.sleep(1)&#10;    &#10;    results = pandas.DataFrame([{&quot;simulation_id&quot;: simulation_id}])&#10;    return results&#10;&#10;&#10;# Ultra-fast version for testing&#10;def rm_main_ultra_fast(data):&#10;    &quot;&quot;&quot;&#10;    Ultra-fast polling for immediate response&#10;    &quot;&quot;&quot;&#10;    print('Starting ULTRA-FAST polling...')&#10;    &#10;    simulation_id = data['simulation_id'].iloc[0]&#10;    api_url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/progress&quot;&#10;    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}&#10;    &#10;    # Check every 0.1 seconds&#10;    while True:&#10;        try:&#10;            response = requests.get(api_url, headers=headers, timeout=3)&#10;            response.raise_for_status()&#10;            data_response = response.json()&#10;            &#10;            status = data_response.get(&quot;status_v5&quot;, &quot;UNKNOWN&quot;)&#10;            print(f&quot;[{time.strftime('%H:%M:%S.%f')[:-3]}] {status}&quot;)&#10;            &#10;            if status == &quot;COMPLETE&quot;:&#10;                print(&quot;✓ DONE!&quot;)&#10;                break&#10;            &#10;            time.sleep(0.1)  # 100ms intervals&#10;            &#10;        except requests.RequestException as e:&#10;            print(f&quot;Error: {e}&quot;)&#10;            time.sleep(0.5)&#10;    &#10;    return pandas.DataFrame([{&quot;simulation_id&quot;: simulation_id}])"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve polling_operator_output (2)" width="90" x="45" y="544">
            <parameter key="repository_entry" value="polling_operator_output"/>
          </operator>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="124" name="MaxWaterLevel (2)" width="90" x="782" y="136">
            <parameter key="script" value="import pandas as pd&#10;import json&#10;import requests&#10;&#10;&#10;def rm_main(simulation_id_df, kafka_input):&#10;    &quot;&quot;&quot;&#10;    Fetch raw point data and return fitness results in GA format&#10;    &quot;&quot;&quot;&#10;    print('Fetching raw point data for GA fitness evaluation...')&#10;&#10;    simulation_id = simulation_id_df.iloc[0]['simulation_id']&#10;    simulation_id = &quot;simulation-3d311164-9783-45a9-a8cc-6b435cceb27b&quot;&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;    &#10;    # Extract optimizer request ID for GA response&#10;    optimizer_request_id = kafka_data.get('optimizerRequestID', '')&#10;    x = 7.459392999&#10;    y = 51.486123&#10;    &#10;    print(f&quot;Optimizer Request ID: {optimizer_request_id}&quot;)&#10;    print(f&quot;URL will be: https://api.floodwaive.de/v1/simulations/{simulation_id}/raw-point-data?x={x}&amp;y={y}&quot;)&#10;    &#10;    try:&#10;        url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/raw-point-data&quot;&#10;        params = {'x': x, 'y': y}&#10;        headers = {&quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;}&#10;        &#10;        response = requests.get(url, headers=headers, params=params)&#10;        &#10;        print(f&quot;Response Status: {response.status_code}&quot;)&#10;        print(f&quot;Raw Response Text: {response.text}&quot;)&#10;        &#10;        if response.status_code == 200:&#10;            api_data = response.json()&#10;            print(f&quot;Parsed JSON: {api_data}&quot;)&#10;            &#10;            # Extract water levels and find maximum&#10;            water_levels = api_data.get('water_levels', [])&#10;            &#10;            if water_levels:&#10;                # Extract all level values&#10;                levels = [entry.get('level', 0.0) for entry in water_levels]&#10;                &#10;                # Find maximum level&#10;                max_level = max(levels)&#10;                &#10;                print(f&quot;Found {len(levels)} water level readings&quot;)&#10;                print(f&quot;Maximum water level: {max_level}&quot;)&#10;                &#10;                # For GA: higher water levels = worse fitness&#10;                # Use max_level as the fitness score (to be minimized)&#10;                fitness_score = max_level&#10;                &#10;            else:&#10;                print(&quot;No water_levels found in response&quot;)&#10;                # High penalty for failed simulations&#10;                fitness_score = 999.0&#10;                &#10;        else:&#10;            print(f&quot;API request failed with status {response.status_code}&quot;)&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            # High penalty for failed API calls&#10;            fitness_score = 999.0&#10;            &#10;    except Exception as e:&#10;        print(f&quot;Error occurred: {e}&quot;)&#10;        # High penalty for errors&#10;        fitness_score = 999.0&#10;    &#10;    # Return GA fitness format&#10;    ga_result = {&#10;        &quot;optimizerRequestID&quot;: optimizer_request_id,&#10;        &quot;simulation_id&quot;: simulation_id,&#10;        &quot;results&quot;: [fitness_score]  # Single fitness value in array&#10;        &#10;        &#10;    }&#10;    &#10;    print(f&quot;Returning GA result: {ga_result}&quot;)&#10;    &#10;    # Return as DataFrame for RapidMiner compatibility&#10;    result_df = pd.DataFrame([ga_result])&#10;    &#10;    return result_df&#10;"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <connect from_port="example set" to_op="Create Measure" to_port="input 1"/>
          <connect from_port="input 1" to_op="Create Measure" to_port="input 2"/>
          <connect from_port="input 2" to_op="Multiply" to_port="input"/>
          <connect from_port="input 3" to_op="CreateSimulation" to_port="input 3"/>
          <connect from_op="Multiply" from_port="output 1" to_op="Create Measure" to_port="input 3"/>
          <connect from_op="Multiply" from_port="output 2" to_op="CreateSimulation" to_port="input 2"/>
          <connect from_op="Multiply" from_port="output 3" to_op="MaxWaterLevel (2)" to_port="input 2"/>
          <connect from_op="Create Measure" from_port="output 1" to_op="CreateSimulation" to_port="input 1"/>
          <connect from_op="CreateSimulation" from_port="output 1" to_op="Polling Operator" to_port="input 1"/>
          <connect from_op="Polling Operator" from_port="output 1" to_op="MaxWaterLevel (2)" to_port="input 1"/>
          <connect from_op="MaxWaterLevel (2)" from_port="output 1" to_port="output 1"/>
          <portSpacing port="source_example set" spacing="0"/>
          <portSpacing port="source_input 1" spacing="0"/>
          <portSpacing port="source_input 2" spacing="231"/>
          <portSpacing port="source_input 3" spacing="0"/>
          <portSpacing port="source_input 4" spacing="0"/>
          <portSpacing port="sink_example set" spacing="0"/>
          <portSpacing port="sink_output 1" spacing="0"/>
          <portSpacing port="sink_output 2" spacing="0"/>
        </process>
        <description align="center" color="transparent" colored="false" width="126">For each Barrier height combination:&lt;br/&gt;Create Barriers &amp;amp; Start simulation</description>
      </operator>
      <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve kafka-no-auth - 2" width="90" x="648" y="34">
        <parameter key="repository_entry" value="/Connections/kafka-no-auth - 2"/>
      </operator>
      <operator activated="false" breakpoints="after" class="store" compatibility="10.5.000" expanded="true" height="68" name="Store (2)" width="90" x="313" y="85">
        <parameter key="repository_entry" value="/data/xy"/>
      </operator>
      <operator activated="false" class="extract_macro" compatibility="10.5.000" expanded="true" height="68" name="Extract Macro" width="90" x="447" y="85">
        <parameter key="macro" value="example"/>
        <parameter key="macro_type" value="number_of_examples"/>
        <parameter key="statistics" value="average"/>
        <parameter key="attribute_name" value=""/>
        <list key="additional_macros"/>
      </operator>
      <operator activated="false" class="concurrency:loop" compatibility="10.5.000" expanded="true" height="145" name="Loop" width="90" x="581" y="136">
        <parameter key="number_of_iterations" value="2"/>
        <parameter key="iteration_macro" value="example"/>
        <parameter key="reuse_results" value="false"/>
        <parameter key="enable_parallel_execution" value="true"/>
        <process expanded="true">
          <operator activated="true" class="multiply" compatibility="10.5.000" expanded="true" height="124" name="Multiply (3)" width="90" x="112" y="391"/>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="145" name="Create Measure (2)" width="90" x="313" y="34">
            <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(elevation_change, op_id, kafka_input, macros):&#10;    row_index = int(macros.get('example'))&#10;    &#10;    print(f&quot;================{row_index-1}=====================&quot;)&#10;    print(&quot;OptimizerID&quot;, op_id.iloc[0]['att0'])&#10;    print(elevation_change.iloc[row_index-1])&#10;    &#10;    # Parse the kafka_input JSON to extract required data&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;    print(kafka_data)&#10;    &#10;    # Extract area_id from the area field and map to correct format&#10;    area_name = kafka_data['area']&#10;    print(area_name)&#10;    &#10;    # Map city names to their corresponding area IDs&#10;    area_mapping = {&#10;        'Dortmund': 'area_20250519130422',&#10;        'Innsbruck': 'area_20250913133225'&#10;    }&#10;    &#10;    area_id = area_mapping.get(area_name, f'area_{area_name}')  # fallback to area_{name} if not found&#10;&#10;    # Get elevation change value for the current row&#10;    current_elevation_change = elevation_change.iloc[row_index-1]&#10;    &#10;    # Extract barriers data which contains tag and geometry&#10;    barriers = kafka_data.get('barriers', [])&#10;    results = []&#10;    &#10;    # Process each barrier and make API calls&#10;    for i, barrier in enumerate(barriers):&#10;        # Extract required fields&#10;        tag = barrier['tag']&#10;        geometry = barrier['geometry']&#10;        barrier_name = barrier['name']&#10;        &#10;        # Get elevation change value - use different value for each barrier&#10;        if hasattr(current_elevation_change, 'iloc') and len(current_elevation_change) &gt; i:&#10;            elevation_value = current_elevation_change.iloc[i]&#10;        elif hasattr(current_elevation_change, 'iloc'):&#10;            elevation_value = current_elevation_change.iloc[0]  # fallback to first if not enough values&#10;        else:&#10;            elevation_value = current_elevation_change&#10;        &#10;        # Prepare the API payload&#10;        payload = {&#10;            &quot;name&quot;: f&quot;RapidMiner Workflow {tag} - {barrier_name}&quot;,&#10;            &quot;tag&quot;: tag,&#10;            &quot;geometry&quot;: geometry,&#10;            &quot;elevation_change&quot;: float(elevation_value),&#10;            &quot;description&quot;: f&quot;A {elevation_value}m high flood {tag.lower()} created via RapidMiner.&quot;&#10;        }&#10;        &#10;        # Make the API call&#10;        try:&#10;            url = f&quot;https://api.floodwaive.de/v1/areas/{area_id}/measures&quot;&#10;            headers = {&#10;                &quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;,&#10;                &quot;Content-Type&quot;: &quot;application/json&quot;&#10;            }&#10;            &#10;            response = requests.post(url, headers=headers, json=payload)&#10;            &#10;            print(f&quot;API call for {barrier_name}:&quot;)&#10;            print(f&quot;Status Code: {response.status_code}&quot;)&#10;            &#10;            if response.status_code == 200:&#10;                print(f&quot;Response: {response.text}&quot;)&#10;                &#10;                response_data = response.json()&#10;                &#10;                # Add to results&#10;                results.append({&#10;                    &quot;measure_id&quot;: response_data.get(&quot;measure_id&quot;),&#10;                    &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                    &quot;area_id&quot;: response_data.get(&quot;area_id&quot;),&#10;                    &quot;tag&quot;: response_data.get(&quot;tag&quot;),&#10;                    &quot;elevation_change&quot;: response_data.get(&quot;elevation_change&quot;),&#10;                    &quot;created_at&quot;: response_data.get(&quot;created_at&quot;),&#10;                    &quot;status&quot;: &quot;success&quot;,&#10;                    &quot;status_code&quot;: response.status_code&#10;                })&#10;                &#10;                print(f&quot;Measure ID: {response_data.get('measure_id')}&quot;)&#10;                &#10;            else:&#10;                print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;                print(f&quot;Response: {response.text}&quot;)&#10;                &#10;                # Add error to results&#10;                results.append({&#10;                    &quot;measure_id&quot;: None,&#10;                    &quot;name&quot;: payload.get(&quot;name&quot;),&#10;                    &quot;area_id&quot;: area_id,&#10;                    &quot;tag&quot;: payload.get(&quot;tag&quot;),&#10;                    &quot;elevation_change&quot;: payload.get(&quot;elevation_change&quot;),&#10;                    &quot;created_at&quot;: None,&#10;                    &quot;status&quot;: &quot;failed&quot;,&#10;                    &quot;status_code&quot;: response.status_code,&#10;                    &quot;error_message&quot;: response.text&#10;                })&#10;                &#10;            print(&quot;=====================================&quot;)&#10;            &#10;        except requests.exceptions.RequestException as e:&#10;            print(f&quot;✗ Error sending request: {e}&quot;)&#10;            print(&quot;=====================================&quot;)&#10;            &#10;            # Add error to results&#10;            results.append({&#10;                &quot;measure_id&quot;: None,&#10;                &quot;name&quot;: payload.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;tag&quot;: payload.get(&quot;tag&quot;),&#10;                &quot;elevation_change&quot;: payload.get(&quot;elevation_change&quot;),&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;error&quot;,&#10;                &quot;status_code&quot;: None,&#10;                &quot;error_message&quot;: str(e)&#10;            })&#10;        &#10;        except Exception as e:&#10;            print(f&quot;✗ Unexpected error for {barrier_name}: {e}&quot;)&#10;            print(&quot;=====================================&quot;)&#10;            &#10;            # Add error to results&#10;            results.append({&#10;                &quot;measure_id&quot;: None,&#10;                &quot;name&quot;: payload.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;tag&quot;: payload.get(&quot;tag&quot;),&#10;                &quot;elevation_change&quot;: payload.get(&quot;elevation_change&quot;),&#10;                &quot;created_at&quot;: None,&#10;                &quot;status&quot;: &quot;error&quot;,&#10;                &quot;status_code&quot;: None,&#10;                &quot;error_message&quot;: str(e)&#10;            })&#10;    &#10;    # Create DataFrame with all results&#10;    result_df = pd.DataFrame(results)&#10;    &#10;    print(&quot;\n&quot; + &quot;=&quot; * 60)&#10;    print(f&quot;Summary: Created {len([r for r in results if r['status'] == 'success'])}/{len(barriers)} barriers successfully&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    return result_df"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="true"/>
            <description align="center" color="transparent" colored="false" width="126">Will be user later&lt;br/&gt;&lt;br/&gt;</description>
          </operator>
          <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve measures-barriers-creation (2)" width="90" x="45" y="748">
            <parameter key="repository_entry" value="measures-barriers-creation"/>
          </operator>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="145" name="CreateSimulation (2)" width="90" x="581" y="85">
            <parameter key="script" value="import requests&#10;import json&#10;import pandas as pd&#10;&#10;def rm_main(measures, kafka_input, rainfall_event):&#10;    &quot;&quot;&quot;&#10;    Alternative version that returns a DataFrame with detailed simulation info&#10;    instead of just the simulation_id&#10;    &quot;&quot;&quot;&#10;    &#10;    print(measures)&#10;    rainfall_event_id = rainfall_event.iloc[0]['rainfall_event_id']&#10;    print(rainfall_event_id)&#10;    &#10;    # Parse the kafka_input JSON to extract required data&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;    print(kafka_data)&#10;    &#10;    # Extract area_id from the area field and map to correct format&#10;    area_name = kafka_data['area']&#10;    &#10;    # Map city names to their corresponding area IDs&#10;    area_mapping = {&#10;        'Dortmund': 'area_20250519130422',&#10;        'Innsbruck': 'area_20250913133225'&#10;    }&#10;    &#10;    area_id = area_mapping.get(area_name, f'area_{area_name}')&#10;    &#10;    # Extract rainfall event name from kafka_data&#10;    rainfall_event_name = kafka_data.get('rainfallEvent', {}).get('name', 'unknown_event')&#10;    &#10;    # Get list of measure IDs from the measures DataFrame&#10;    measure_ids = measures['measure_id'].tolist()&#10;    &#10;    # Prepare the API payload for simulation&#10;    simulation_name = f&quot;Optimizer {rainfall_event_name} Simulation&quot;&#10;    &#10;    payload = {&#10;        &quot;name&quot;: simulation_name,&#10;        &quot;model_id&quot;: &quot;deepwaive-4.0-pre-latest&quot;,&#10;        &quot;resolution&quot;: 4,&#10;        &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;        &quot;measures&quot;: measure_ids&#10;    }&#10;    &#10;    print(f&quot;Creating simulation with {len(measure_ids)} measures:&quot;)&#10;    print(f&quot;Area ID: {area_id}&quot;)&#10;    print(f&quot;Simulation Name: {simulation_name}&quot;)&#10;    print(f&quot;Rainfall Event ID: {rainfall_event_id}&quot;)&#10;    print(f&quot;Measures: {measure_ids}&quot;)&#10;    &#10;    # Make the API call to create simulation&#10;    try:&#10;        url = f&quot;https://api.floodwaive.de/v1/areas/{area_id}/simulations&quot;&#10;        headers = {&#10;            &quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;,&#10;            &quot;Content-Type&quot;: &quot;application/json&quot;&#10;        }&#10;        &#10;        response = requests.post(url, headers=headers, json=payload)&#10;        &#10;        print(f&quot;\nAPI call to create simulation:&quot;)&#10;        print(f&quot;URL: {url}&quot;)&#10;        print(f&quot;Status Code: {response.status_code}&quot;)&#10;        &#10;        if response.status_code in [200, 201]:  # Success codes&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            &#10;            response_data = response.json()&#10;            simulation_id = response_data.get(&quot;simulation_id&quot;) or response_data.get(&quot;id&quot;)&#10;            &#10;            print(f&quot;✓ Simulation created successfully!&quot;)&#10;            print(f&quot;Simulation ID: {simulation_id}&quot;)&#10;            &#10;            # Create result dictionary&#10;            result = {&#10;                &quot;simulation_id&quot;: simulation_id,&#10;                &quot;name&quot;: response_data.get(&quot;name&quot;),&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;                &quot;measures_count&quot;: len(measure_ids),&#10;                &quot;status&quot;: &quot;success&quot;,&#10;                &quot;status_code&quot;: response.status_code,&#10;                &quot;created_at&quot;: response_data.get(&quot;created_at&quot;)&#10;            }&#10;            &#10;        else:&#10;            print(f&quot;✗ Request failed with status code {response.status_code}&quot;)&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            &#10;            # Create error result&#10;            result = {&#10;                &quot;simulation_id&quot;: None,&#10;                &quot;name&quot;: simulation_name,&#10;                &quot;area_id&quot;: area_id,&#10;                &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;                &quot;measures_count&quot;: len(measure_ids),&#10;                &quot;status&quot;: &quot;failed&quot;,&#10;                &quot;status_code&quot;: response.status_code,&#10;                &quot;error_message&quot;: response.text,&#10;                &quot;created_at&quot;: None&#10;            }&#10;            &#10;    except Exception as e:&#10;        print(f&quot;✗ Error: {e}&quot;)&#10;        &#10;        # Create error result&#10;        result = {&#10;            &quot;simulation_id&quot;: None,&#10;            &quot;name&quot;: simulation_name,&#10;            &quot;area_id&quot;: area_id,&#10;            &quot;rainfall_event_id&quot;: rainfall_event_id,&#10;            &quot;measures_count&quot;: len(measure_ids),&#10;            &quot;status&quot;: &quot;error&quot;,&#10;            &quot;status_code&quot;: None,&#10;            &quot;error_message&quot;: str(e),&#10;            &quot;created_at&quot;: None&#10;        }&#10;    &#10;    # Return DataFrame with simulation details&#10;    result_df = pd.DataFrame([result])&#10;    &#10;    print(f&quot;\nSummary:&quot;)&#10;    print(f&quot;Status: {result['status']}&quot;)&#10;    print(f&quot;Simulation ID: {result.get('simulation_id')}&quot;)&#10;    print(&quot;=&quot; * 60)&#10;    &#10;    return result_df"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="103" name="Polling Operator (2)" width="90" x="715" y="85">
            <parameter key="script" value="import pandas&#10;import requests&#10;import time&#10;import json&#10;&#10;# Configuration&#10;API_TOKEN = &quot;fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;&#10;&#10;# Polling config - SHORTER INTERVALS&#10;INITIAL_INTERVAL = 0.5  # Start with 0.5 seconds instead of 2&#10;MAX_INTERVAL = 10       # Max 10 seconds instead of 30&#10;BACKOFF_MULTIPLIER = 1.2  # Slower backoff (1.2 instead of 1.5)&#10;&#10;def poll_simulation(simulation_id):&#10;    &quot;&quot;&quot;Poll simulation endpoint until COMPLETE status&quot;&quot;&quot;&#10;    api_url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/progress&quot;&#10;    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}&#10;    &#10;    interval = INITIAL_INTERVAL&#10;    last_status = None&#10;    &#10;    while True:&#10;        try:&#10;            response = requests.get(api_url, headers=headers, timeout=10)&#10;            response.raise_for_status()&#10;            data = response.json()&#10;            &#10;            status = data.get(&quot;status_v5&quot;, &quot;UNKNOWN&quot;)&#10;            print(f&quot;[{time.strftime('%H:%M:%S')}] Status: {status}&quot;)&#10;            &#10;            if status == &quot;COMPLETE&quot;:&#10;                print(&quot;✓ Simulation complete!&quot;)&#10;                return data&#10;            &#10;            # Reset interval if status changed&#10;            if status != last_status:&#10;                interval = INITIAL_INTERVAL&#10;                last_status = status&#10;            else:&#10;                interval = min(interval * BACKOFF_MULTIPLIER, MAX_INTERVAL)&#10;            &#10;            print(f&quot;Waiting {interval:.1f}s...&quot;)&#10;            time.sleep(interval)&#10;            &#10;        except requests.RequestException as e:&#10;            print(f&quot;Error: {e}. Retrying in 2s...&quot;)  # Shorter retry interval too&#10;            time.sleep(2)&#10;&#10;def rm_main(data):&#10;    &quot;&quot;&quot;&#10;    RapidMiner main function&#10;    Input: DataFrame with 'simulation_id' column&#10;    Output: Original data + Results DataFrame with simulation_id&#10;    &quot;&quot;&quot;&#10;    print('Starting simulation polling...')&#10;    &#10;    # Get simulation ID from input data&#10;    if 'simulation_id' not in data.columns:&#10;        raise ValueError(&quot;Input data must contain 'simulation_id' column&quot;)&#10;    &#10;    simulation_id = data['simulation_id'].iloc[0]&#10;    print(f&quot;Monitoring simulation: {simulation_id}&quot;)&#10;    &#10;    # Poll until complete&#10;    completion_data = poll_simulation(simulation_id)&#10;    &#10;    # Return only simulation_id as DataFrame&#10;    results = pandas.DataFrame([{&quot;simulation_id&quot;: simulation_id}])&#10;    &#10;    return results&#10;&#10;&#10;# Alternative version with even more aggressive polling&#10;def rm_main_fast(data):&#10;    &quot;&quot;&quot;&#10;    Very fast polling version&#10;    &quot;&quot;&quot;&#10;    print('Starting FAST simulation polling...')&#10;    &#10;    simulation_id = data['simulation_id'].iloc[0]&#10;    print(f&quot;Monitoring simulation: {simulation_id}&quot;)&#10;    &#10;    api_url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/progress&quot;&#10;    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}&#10;    &#10;    # Very aggressive polling - check every 0.2 seconds initially&#10;    interval = 0.2&#10;    max_interval = 5&#10;    &#10;    while True:&#10;        try:&#10;            response = requests.get(api_url, headers=headers, timeout=5)&#10;            response.raise_for_status()&#10;            data_response = response.json()&#10;            &#10;            status = data_response.get(&quot;status_v5&quot;, &quot;UNKNOWN&quot;)&#10;            print(f&quot;[{time.strftime('%H:%M:%S.%f')[:-3]}] Status: {status}&quot;)&#10;            &#10;            if status == &quot;COMPLETE&quot;:&#10;                print(&quot;✓ Simulation complete!&quot;)&#10;                break&#10;            &#10;            # Gradual backoff but stay aggressive&#10;            time.sleep(interval)&#10;            interval = min(interval * 1.1, max_interval)&#10;            &#10;        except requests.RequestException as e:&#10;            print(f&quot;Error: {e}. Retrying in 1s...&quot;)&#10;            time.sleep(1)&#10;    &#10;    results = pandas.DataFrame([{&quot;simulation_id&quot;: simulation_id}])&#10;    return results&#10;&#10;&#10;# Ultra-fast version for testing&#10;def rm_main_ultra_fast(data):&#10;    &quot;&quot;&quot;&#10;    Ultra-fast polling for immediate response&#10;    &quot;&quot;&quot;&#10;    print('Starting ULTRA-FAST polling...')&#10;    &#10;    simulation_id = data['simulation_id'].iloc[0]&#10;    api_url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/progress&quot;&#10;    headers = {&quot;Authorization&quot;: f&quot;Bearer {API_TOKEN}&quot;}&#10;    &#10;    # Check every 0.1 seconds&#10;    while True:&#10;        try:&#10;            response = requests.get(api_url, headers=headers, timeout=3)&#10;            response.raise_for_status()&#10;            data_response = response.json()&#10;            &#10;            status = data_response.get(&quot;status_v5&quot;, &quot;UNKNOWN&quot;)&#10;            print(f&quot;[{time.strftime('%H:%M:%S.%f')[:-3]}] {status}&quot;)&#10;            &#10;            if status == &quot;COMPLETE&quot;:&#10;                print(&quot;✓ DONE!&quot;)&#10;                break&#10;            &#10;            time.sleep(0.1)  # 100ms intervals&#10;            &#10;        except requests.RequestException as e:&#10;            print(f&quot;Error: {e}&quot;)&#10;            time.sleep(0.5)&#10;    &#10;    return pandas.DataFrame([{&quot;simulation_id&quot;: simulation_id}])"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="false"/>
          </operator>
          <operator activated="false" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve polling_operator_output" width="90" x="45" y="646">
            <parameter key="repository_entry" value="polling_operator_output"/>
          </operator>
          <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="124" name="MaxWaterLevel" width="90" x="916" y="238">
            <parameter key="script" value="import pandas as pd&#10;import json&#10;import requests&#10;&#10;&#10;def rm_main(simulation_id_df, kafka_input, macros):&#10;    &quot;&quot;&quot;&#10;    Fetch raw point data and return fitness results in GA format&#10;    &quot;&quot;&quot;&#10;    print('Fetching raw point data for GA fitness evaluation...')&#10;&#10;    simulation_id = simulation_id_df.iloc[0]['simulation_id']&#10;    simulation_id = &quot;simulation-3d311164-9783-45a9-a8cc-6b435cceb27b&quot;&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;    &#10;    # Extract optimizer request ID for GA response&#10;    optimizer_request_id = kafka_data.get('optimizerRequestID', '')&#10;    x = 7.459392999&#10;    y = 51.486123&#10;    &#10;    print(f&quot;Optimizer Request ID: {optimizer_request_id}&quot;)&#10;    print(f&quot;URL will be: https://api.floodwaive.de/v1/simulations/{simulation_id}/raw-point-data?x={x}&amp;y={y}&quot;)&#10;    &#10;    try:&#10;        url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/raw-point-data&quot;&#10;        params = {'x': x, 'y': y}&#10;        headers = {&quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;}&#10;        &#10;        response = requests.get(url, headers=headers, params=params)&#10;        &#10;        print(f&quot;Response Status: {response.status_code}&quot;)&#10;        print(f&quot;Raw Response Text: {response.text}&quot;)&#10;        &#10;        if response.status_code == 200:&#10;            api_data = response.json()&#10;            print(f&quot;Parsed JSON: {api_data}&quot;)&#10;            &#10;            # Extract water levels and find maximum&#10;            water_levels = api_data.get('water_levels', [])&#10;            &#10;            if water_levels:&#10;                # Extract all level values&#10;                levels = [entry.get('level', 0.0) for entry in water_levels]&#10;                &#10;                # Find maximum level&#10;                max_level = max(levels)&#10;                &#10;                print(f&quot;Found {len(levels)} water level readings&quot;)&#10;                print(f&quot;Maximum water level: {max_level}&quot;)&#10;                &#10;                # For GA: higher water levels = worse fitness&#10;                # Use max_level as the fitness score (to be minimized)&#10;                row_index = int(macros.get('example'))&#10;                fitness_score = max_level + row_index&#10;                &#10;            else:&#10;                print(&quot;No water_levels found in response&quot;)&#10;                # High penalty for failed simulations&#10;                fitness_score = 999.0&#10;                &#10;        else:&#10;            print(f&quot;API request failed with status {response.status_code}&quot;)&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            # High penalty for failed API calls&#10;            fitness_score = 999.0&#10;            &#10;    except Exception as e:&#10;        print(f&quot;Error occurred: {e}&quot;)&#10;        # High penalty for errors&#10;        fitness_score = 999.0&#10;    &#10;    # Return GA fitness format&#10;    ga_result = {&#10;        &quot;optimizerRequestID&quot;: optimizer_request_id,&#10;        &quot;simulation_id&quot;: simulation_id,&#10;        &quot;results&quot;: [fitness_score]  # Single fitness value in array&#10;        &#10;        &#10;    }&#10;    &#10;    print(f&quot;Returning GA result: {ga_result}&quot;)&#10;    &#10;    # Return as DataFrame for RapidMiner compatibility&#10;    result_df = pd.DataFrame([ga_result])&#10;    &#10;    return result_df&#10;"/>
            <parameter key="notebook_cell_tag_filter" value=""/>
            <parameter key="use_default_python" value="true"/>
            <parameter key="package_manager" value="conda (anaconda)"/>
            <parameter key="use_macros" value="true"/>
          </operator>
          <operator activated="true" class="log" compatibility="10.5.000" expanded="true" height="82" name="Log" width="90" x="1117" y="136">
            <list key="log">
              <parameter key="sim" value="operator.CreateSimulation.parameter.script"/>
            </list>
            <parameter key="sorting_type" value="none"/>
            <parameter key="sorting_k" value="100"/>
            <parameter key="persistent" value="false"/>
            <description align="center" color="transparent" colored="false" width="126">inside the loop</description>
          </operator>
          <operator activated="true" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve polling_operator_output (3)" width="90" x="581" y="442">
            <parameter key="repository_entry" value="polling_operator_output"/>
          </operator>
          <connect from_port="input 1" to_op="Create Measure (2)" to_port="input 1"/>
          <connect from_port="input 2" to_op="Create Measure (2)" to_port="input 2"/>
          <connect from_port="input 3" to_op="Multiply (3)" to_port="input"/>
          <connect from_port="input 4" to_op="CreateSimulation (2)" to_port="input 3"/>
          <connect from_op="Multiply (3)" from_port="output 1" to_op="Create Measure (2)" to_port="input 3"/>
          <connect from_op="Multiply (3)" from_port="output 2" to_op="CreateSimulation (2)" to_port="input 2"/>
          <connect from_op="Multiply (3)" from_port="output 3" to_op="MaxWaterLevel" to_port="input 2"/>
          <connect from_op="Create Measure (2)" from_port="output 1" to_op="CreateSimulation (2)" to_port="input 1"/>
          <connect from_op="CreateSimulation (2)" from_port="output 1" to_op="Polling Operator (2)" to_port="input 1"/>
          <connect from_op="Polling Operator (2)" from_port="output 1" to_op="MaxWaterLevel" to_port="input 1"/>
          <connect from_op="MaxWaterLevel" from_port="output 1" to_op="Log" to_port="through 1"/>
          <connect from_op="Log" from_port="through 1" to_port="output 1"/>
          <portSpacing port="source_input 1" spacing="0"/>
          <portSpacing port="source_input 2" spacing="0"/>
          <portSpacing port="source_input 3" spacing="0"/>
          <portSpacing port="source_input 4" spacing="0"/>
          <portSpacing port="source_input 5" spacing="0"/>
          <portSpacing port="sink_output 1" spacing="0"/>
          <portSpacing port="sink_output 2" spacing="0"/>
        </process>
      </operator>
      <operator activated="false" class="append" compatibility="10.5.000" expanded="true" height="82" name="Append" width="90" x="715" y="238">
        <parameter key="data_management" value="auto"/>
        <parameter key="merge_type" value="all"/>
      </operator>
      <operator activated="false" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="103" name="Aggregated data" width="90" x="849" y="238">
        <parameter key="script" value="import pandas as pd&#10;import ast&#10;def rm_main(data):&#10;    print(&quot;Input data:&quot;)&#10;    print(data)&#10;    &#10;    if len(data) == 0:&#10;        return pd.DataFrame()&#10;    &#10;    # Get the unique optimizerRequestID and simulation_id (should be same for all rows)&#10;    optimizer_request_id = str(data['optimizerRequestID'].iloc[0])&#10;    simulation_id = str(data['simulation_id'].iloc[0])&#10;    &#10;    # Extract and combine all results into a single list&#10;    all_results = []&#10;    &#10;    for idx, row in data.iterrows():&#10;        result = row['results']&#10;        &#10;        # Handle different possible formats of results&#10;        if isinstance(result, str):&#10;            try:&#10;                # Try to parse as list string like &quot;[0.01000213623046875]&quot;&#10;                parsed_result = ast.literal_eval(result)&#10;                if isinstance(parsed_result, list):&#10;                    all_results.extend(parsed_result)&#10;                else:&#10;                    all_results.append(float(parsed_result))&#10;            except (ValueError, SyntaxError):&#10;                # If parsing fails, try to convert directly to float&#10;                try:&#10;                    all_results.append(float(result))&#10;                except ValueError:&#10;                    print(f&quot;Warning: Could not parse result: {result}&quot;)&#10;        elif isinstance(result, list):&#10;            # Already a list, extend the main list&#10;            all_results.extend(result)&#10;        elif isinstance(result, (int, float)):&#10;            # Single numeric value&#10;            all_results.append(float(result))&#10;        else:&#10;            print(f&quot;Warning: Unknown result format: {type(result)} - {result}&quot;)&#10;    &#10;    # Create single-row DataFrame&#10;    aggregated_data = pd.DataFrame({&#10;        'optimizerRequestID': [optimizer_request_id],&#10;        'simulation_id': [simulation_id],&#10;        'results': [all_results]&#10;    })&#10;    &#10;    print(&quot;\nAggregated data:&quot;)&#10;    print(aggregated_data)&#10;    print(f&quot;\nResults list length: {len(all_results)}&quot;)&#10;    print(f&quot;Results: {all_results}&quot;)&#10;    &#10;    return aggregated_data"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <operator activated="false" breakpoints="after" class="log_to_data" compatibility="10.5.000" expanded="true" height="103" name="Log to Data" width="90" x="983" y="136">
        <description align="center" color="transparent" colored="false" width="126">after agg data&lt;br/&gt;</description>
      </operator>
      <operator activated="false" class="store" compatibility="10.5.000" expanded="true" height="68" name="Store" width="90" x="1117" y="85">
        <parameter key="repository_entry" value="logs"/>
      </operator>
      <operator activated="false" class="kafka_connector:write_kafka_topic" compatibility="0.3.002" expanded="true" height="82" name="Write Kafka Topic" width="90" x="1251" y="34">
        <parameter key="kafka_topic" value="ga_in"/>
        <parameter key="attribute_separator" value=";"/>
        <parameter key="bulk_sending" value="false"/>
        <parameter key="message_interval" value="1"/>
        <parameter key="message_format" value="JSON"/>
        <parameter key="api_timeout" value="5000"/>
      </operator>
      <operator activated="true" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve polling_operator_output (4)" width="90" x="447" y="289">
        <parameter key="repository_entry" value="polling_operator_output"/>
      </operator>
      <operator activated="true" class="python_scripting:execute_python" compatibility="10.1.002" expanded="true" height="124" name="MaxWaterLevel (3)" width="90" x="514" y="493">
        <parameter key="script" value="import pandas as pd&#10;import json&#10;import requests&#10;&#10;&#10;def rm_main(simulation_id_df, kafka_input):&#10;    &quot;&quot;&quot;&#10;    Fetch raw point data and return fitness results in GA format&#10;    &quot;&quot;&quot;&#10;    print('Fetching raw point data for GA fitness evaluation...')&#10;&#10;    simulation_id = simulation_id_df.iloc[0]['simulation_id']&#10;    kafka_data = json.loads(kafka_input.iloc[-1]['value'])&#10;&#10;    poi = kafka_data.get('pointOfInterest', '')&#10;    optimizer_request_id = kafka_data.get('optimizerRequestID', '')&#10;&#10;    &#10;    x = poi['longitude']&#10;    y = poi['latitude']&#10;&#10;&#10;    print(f&quot;Optimizer Request ID: {optimizer_request_id}&quot;)&#10;    print(f&quot;URL will be: https://api.floodwaive.de/v1/simulations/{simulation_id}/raw-point-data?x={x}&amp;y={y}&quot;)&#10;    &#10;    try:&#10;        url = f&quot;https://api.floodwaive.de/v1/simulations/{simulation_id}/raw-point-data&quot;&#10;        params = {'x': x, 'y': y}&#10;        headers = {&quot;Authorization&quot;: &quot;Bearer fw_ba692f29ca5d40cdbae6c6fd75179a3a&quot;}&#10;        &#10;        response = requests.get(url, headers=headers, params=params)&#10;        &#10;        print(f&quot;Response Status: {response.status_code}&quot;)&#10;        print(f&quot;Raw Response Text: {response.text}&quot;)&#10;        &#10;        if response.status_code == 200:&#10;            api_data = response.json()&#10;            print(f&quot;Parsed JSON: {api_data}&quot;)&#10;            &#10;            # Extract water levels and find maximum&#10;            water_levels = api_data.get('water_levels', [])&#10;            &#10;            if water_levels:&#10;                # Extract all level values&#10;                levels = [entry.get('level', 0.0) for entry in water_levels]&#10;                &#10;                # Find maximum level&#10;                max_level = max(levels)&#10;                &#10;                print(f&quot;Found {len(levels)} water level readings&quot;)&#10;                print(f&quot;Maximum water level: {max_level}&quot;)&#10;                &#10;                # For GA: higher water levels = worse fitness&#10;                # Use max_level as the fitness score (to be minimized)&#10;                fitness_score = max_level&#10;                &#10;            else:&#10;                print(&quot;No water_levels found in response&quot;)&#10;                # High penalty for failed simulations&#10;                fitness_score = 404.0&#10;                &#10;        else:&#10;            print(f&quot;API request failed with status {response.status_code}&quot;)&#10;            print(f&quot;Response: {response.text}&quot;)&#10;            # High penalty for failed API calls&#10;            fitness_score = 999.0&#10;            &#10;    except Exception as e:&#10;        print(f&quot;Error occurred: {e}&quot;)&#10;        # High penalty for errors&#10;        fitness_score = -1&#10;    &#10;    # Return GA fitness format&#10;    ga_result = {&#10;        &quot;optimizerRequestID&quot;: optimizer_request_id,&#10;        &quot;simulation_id&quot;: simulation_id,&#10;        &quot;results&quot;: [fitness_score]  # Single fitness value in array&#10;        &#10;        &#10;    }&#10;    &#10;    print(f&quot;Returning GA result: {ga_result}&quot;)&#10;    &#10;    # Return as DataFrame for RapidMiner compatibility&#10;    result_df = pd.DataFrame([ga_result])&#10;    &#10;    return result_df&#10;"/>
        <parameter key="notebook_cell_tag_filter" value=""/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="use_macros" value="false"/>
      </operator>
      <connect from_op="pops" from_port="output" to_op="Execute Python" to_port="input 1"/>
      <connect from_op="Execute Python" from_port="output 1" to_op="Store (2)" to_port="input"/>
      <connect from_op="Retrieve polling-operator-output" from_port="output" to_op="Append (2)" to_port="example set 1"/>
      <connect from_op="Retrieve Optimizer-Input-Kafka" from_port="output" to_op="Multiply (2)" to_port="input"/>
      <connect from_op="Multiply (2)" from_port="output 1" to_op="Create Rainfall event (2)" to_port="input 1"/>
      <connect from_op="Multiply (2)" from_port="output 2" to_op="MaxWaterLevel (3)" to_port="input 2"/>
      <connect from_op="Retrieve kafka-no-auth - 2" from_port="output" to_op="Write Kafka Topic" to_port="connection"/>
      <connect from_op="Extract Macro" from_port="example set" to_op="Loop" to_port="input 1"/>
      <connect from_op="Loop" from_port="output 1" to_op="Append" to_port="example set 1"/>
      <connect from_op="Append" from_port="merged set" to_op="Aggregated data" to_port="input 1"/>
      <connect from_op="Aggregated data" from_port="output 1" to_op="Log to Data" to_port="through 1"/>
      <connect from_op="Log to Data" from_port="exampleSet" to_op="Store" to_port="input"/>
      <connect from_op="Store" from_port="through" to_op="Write Kafka Topic" to_port="input"/>
      <connect from_op="Retrieve polling_operator_output (4)" from_port="output" to_op="MaxWaterLevel (3)" to_port="input 1"/>
      <connect from_op="MaxWaterLevel (3)" from_port="output 1" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
    </process>
  </operator>
</process>
