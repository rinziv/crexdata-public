<?xml version="1.0" encoding="UTF-8"?><process version="10.5.000">
  <context>
    <input>
      <location>../data/testExampleSet</location>
    </input>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="10.5.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="python_scripting:python_transformer" compatibility="10.1.002" expanded="true" height="68" name="Revelance Predictor" width="90" x="380" y="136">
        <parameter key="editable" value="true"/>
        <parameter key="operator" value="{&#10;  &quot;name&quot;: &quot;Revelance Predictor&quot;,&#10;  &quot;dropSpecial&quot;: false,&#10;  &quot;parameters&quot;: [&#10;    {&#10;      &quot;name&quot;: &quot;model_name&quot;,&#10;      &quot;type&quot;: &quot;string&quot;,&#10;      &quot;description&quot;: &quot;By default parameters are of type string\.&quot;,&#10;      &quot;optional&quot;: false&#10;    },&#10;    {&#10;      &quot;name&quot;: &quot;text_header_name&quot;,&#10;      &quot;type&quot;: &quot;string&quot;,&#10;      &quot;description&quot;: &quot;By default parameters are of type string\.&quot;,&#10;      &quot;optional&quot;: false&#10;    }&#10;  ],&#10;  &quot;inputs&quot;: [&#10;    {&#10;      &quot;name&quot;: &quot;data&quot;,&#10;      &quot;type&quot;: &quot;table&quot;&#10;    }&#10;  ],&#10;  &quot;outputs&quot;: [&#10;    {&#10;      &quot;name&quot;: &quot;out&quot;,&#10;      &quot;type&quot;: &quot;table&quot;&#10;    }&#10;  ]&#10;}.import os&#10;from pandas import DataFrame&#10;from transformers import pipeline as tpipline&#10;from tqdm import tqdm&#10;&#10;&#10;def rm_main(data, parameters):&#10;&#9;predictions, scores = [], []&#10;&#9;model_path = os\.path\.join(os\.path\.dirname(os\.getcwd()), &quot;models&quot;, parameters[&quot;model_name&quot;]) &#10;&#9;model = tpipline(task=&quot;text-classification&quot;, model=model_path, batch_size=512)&#10;&#9;tokenizer_kwargs = {'padding': True, 'truncation': True, 'max_length': 512}&#10;&#9;for text in data[parameters[&quot;text_header_name&quot;]]\.to_list():&#10;&#9;&#9;pred = model(text, **tokenizer_kwargs)[0]&#10;&#9;&#9;&#10;&#9;&#9;predictions\.append(pred[&quot;label&quot;])&#10;&#9;&#9;scores\.append(pred[&quot;score&quot;])&#10;&#10;&#9;data[&quot;event_class&quot;] = predictions&#10;&#9;data[&quot;event_score&quot;] = scores&#10;&#10;&#9;return data"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="model_name" value="relevance-model-distilled-31624953"/>
        <parameter key="text_header_name" value="tweet_text"/>
        <description align="center" color="transparent" colored="false" width="126">Custom Operator</description>
      </operator>
      <connect from_port="input 1" to_op="Revelance Predictor" to_port="data"/>
      <connect from_op="Revelance Predictor" from_port="out" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="source_input 2" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
    </process>
  </operator>
</process>
