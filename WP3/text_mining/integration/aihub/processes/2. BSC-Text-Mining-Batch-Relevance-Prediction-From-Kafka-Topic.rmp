<?xml version="1.0" encoding="UTF-8"?><process version="10.5.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="10.5.000" expanded="true" name="Process" origin="GENERATED_TUTORIAL">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="retrieve" compatibility="10.5.000" expanded="true" height="68" name="Retrieve server-crexdata-eu-no-auth" width="90" x="179" y="136">
        <parameter key="repository_entry" value="/Connections/server-crexdata-eu-no-auth"/>
      </operator>
      <operator activated="true" class="multiply" compatibility="10.5.000" expanded="true" height="103" name="Multiply" width="90" x="313" y="136"/>
      <operator activated="true" class="kafka_connector:read_kafka_topic" compatibility="0.3.002" expanded="true" height="82" name="Read Kafka Topic" width="90" x="447" y="187">
        <parameter key="kafka_topic" value="text_mining_test_topic_1"/>
        <parameter key="offset_strategy" value="earliest"/>
        <parameter key="retrieval_time_out" value="5"/>
        <parameter key="get_all" value="true"/>
        <parameter key="number_of_records" value="100"/>
        <parameter key="collection_strategy" value="duration"/>
        <parameter key="counter" value="100"/>
        <parameter key="time_out" value="120"/>
        <parameter key="polling_time_out" value="5"/>
        <parameter key="api_timeout" value="10"/>
        <description align="center" color="transparent" colored="false" width="126">Add topic with tweets in &amp;quot;tweet_text&amp;quot; field</description>
      </operator>
      <operator activated="true" class="blending:select_attributes" compatibility="10.5.000" expanded="true" height="82" name="Select Attributes" width="90" x="514" y="340">
        <parameter key="type" value="include attributes"/>
        <parameter key="attribute_filter_type" value="one attribute"/>
        <parameter key="select_attribute" value="value"/>
        <parameter key="select_subset" value=""/>
        <parameter key="also_apply_to_special_attributes_(id,_label..)" value="false"/>
      </operator>
      <operator activated="true" class="text:data_to_documents" compatibility="10.1.000" expanded="true" height="68" name="Data to Documents" width="90" x="648" y="340">
        <parameter key="select_attributes_and_weights" value="false"/>
        <list key="specify_weights"/>
      </operator>
      <operator activated="true" class="text:json_to_data" compatibility="10.1.000" expanded="true" height="82" name="JSON To Data" width="90" x="782" y="340">
        <parameter key="ignore_arrays" value="false"/>
        <parameter key="limit_attributes" value="false"/>
        <parameter key="skip_invalid_documents" value="false"/>
        <parameter key="guess_data_types" value="true"/>
        <parameter key="keep_missing_attributes" value="false"/>
        <parameter key="missing_values_aliases" value=", null, NaN, missing"/>
        <parameter key="preserve_attribute_order" value="false"/>
      </operator>
      <operator activated="true" class="python_scripting:python_transformer" compatibility="10.1.002" expanded="true" height="68" name="Revelance Prediction" width="90" x="916" y="340">
        <parameter key="editable" value="true"/>
        <parameter key="operator" value="{&#10;  &quot;name&quot;: &quot;Revelance Predictor&quot;,&#10;  &quot;dropSpecial&quot;: false,&#10;  &quot;parameters&quot;: [&#10;    {&#10;      &quot;name&quot;: &quot;model_name&quot;,&#10;      &quot;type&quot;: &quot;string&quot;,&#10;      &quot;description&quot;: &quot;By default parameters are of type string\.&quot;,&#10;      &quot;optional&quot;: false&#10;    },&#10;    {&#10;      &quot;name&quot;: &quot;text_header_name&quot;,&#10;      &quot;type&quot;: &quot;string&quot;,&#10;      &quot;description&quot;: &quot;By default parameters are of type string\.&quot;,&#10;      &quot;optional&quot;: false&#10;    }&#10;  ],&#10;  &quot;inputs&quot;: [&#10;    {&#10;      &quot;name&quot;: &quot;data&quot;,&#10;      &quot;type&quot;: &quot;table&quot;&#10;    }&#10;  ],&#10;  &quot;outputs&quot;: [&#10;    {&#10;      &quot;name&quot;: &quot;out&quot;,&#10;      &quot;type&quot;: &quot;table&quot;&#10;    }&#10;  ]&#10;}.import os&#10;from pandas import DataFrame&#10;from transformers import pipeline as tpipline&#10;from tqdm import tqdm&#10;&#10;&#10;def rm_main(data, parameters):&#10;&#9;predictions, scores = [], []&#10;&#9;model_path = os\.path\.join(os\.path\.dirname(os\.getcwd()), &quot;models&quot;, parameters[&quot;model_name&quot;])&#10;&#9;model = tpipline(task=&quot;text-classification&quot;, model=model_path, batch_size=512)&#10;&#9;tokenizer_kwargs = {'padding': True, 'truncation': True, 'max_length': 512}&#10;&#9;for text in data[parameters[&quot;text_header_name&quot;]]\.to_list():&#10;&#9;&#9;pred = model(text, **tokenizer_kwargs)[0]&#10;&#9;&#9;&#10;&#9;&#9;predictions\.append(pred[&quot;label&quot;])&#10;&#9;&#9;scores\.append(pred[&quot;score&quot;])&#10;&#10;&#9;data[&quot;event_class&quot;] = predictions&#10;&#9;data[&quot;event_score&quot;] = scores&#10;&#10;&#9;return data"/>
        <parameter key="use_default_python" value="true"/>
        <parameter key="package_manager" value="conda (anaconda)"/>
        <parameter key="model_name" value="relevance-model-distilled-31624953"/>
        <parameter key="text_header_name" value="tweet_text"/>
        <description align="center" color="transparent" colored="false" width="126">Custom Operator</description>
      </operator>
      <operator activated="true" class="select_subprocess" compatibility="10.5.000" expanded="true" height="103" name="Save to CSV or Kafka" width="90" x="1050" y="85">
        <parameter key="select_which" value="1"/>
        <process expanded="true">
          <operator activated="true" class="write_csv" compatibility="10.5.000" expanded="true" height="82" name="Write CSV" width="90" x="179" y="34">
            <parameter key="csv_file" value="../data/output.csv"/>
            <parameter key="column_separator" value=","/>
            <parameter key="write_attribute_names" value="true"/>
            <parameter key="quote_nominal_values" value="true"/>
            <parameter key="format_date_attributes" value="true"/>
            <parameter key="date_format" value="yyyy-MM-dd HH:mm:ss"/>
            <parameter key="append_to_file" value="false"/>
            <parameter key="encoding" value="SYSTEM"/>
          </operator>
          <operator activated="true" class="write_file" compatibility="10.5.000" expanded="true" height="68" name="Write File" width="90" x="380" y="85">
            <parameter key="resource_type" value="repository blob entry"/>
            <parameter key="repository_entry" value="../data/prediction_output_30252130.csv"/>
            <parameter key="mime_type" value="text/csv"/>
          </operator>
          <connect from_port="input 1" to_op="Write CSV" to_port="input"/>
          <connect from_op="Write CSV" from_port="through" to_port="output 1"/>
          <connect from_op="Write CSV" from_port="file" to_op="Write File" to_port="file"/>
          <portSpacing port="source_input 1" spacing="0"/>
          <portSpacing port="source_input 2" spacing="0"/>
          <portSpacing port="source_input 3" spacing="0"/>
          <portSpacing port="sink_output 1" spacing="0"/>
          <portSpacing port="sink_output 2" spacing="0"/>
        </process>
        <process expanded="true">
          <operator activated="true" class="kafka_connector:write_kafka_topic" compatibility="0.3.002" expanded="true" height="82" name="Write Kafka Topic" width="90" x="112" y="34">
            <parameter key="kafka_topic" value="text_mining_test_topic_2"/>
            <parameter key="attribute_separator" value=";"/>
            <parameter key="bulk_sending" value="false"/>
            <parameter key="message_interval" value="1"/>
            <parameter key="message_format" value="JSON"/>
            <parameter key="api_timeout" value="5000"/>
          </operator>
          <connect from_port="input 1" to_op="Write Kafka Topic" to_port="input"/>
          <connect from_port="input 2" to_op="Write Kafka Topic" to_port="connection"/>
          <connect from_op="Write Kafka Topic" from_port="throughput" to_port="output 1"/>
          <portSpacing port="source_input 1" spacing="0"/>
          <portSpacing port="source_input 2" spacing="0"/>
          <portSpacing port="source_input 3" spacing="0"/>
          <portSpacing port="sink_output 1" spacing="0"/>
          <portSpacing port="sink_output 2" spacing="0"/>
        </process>
        <description align="center" color="transparent" colored="false" width="126">Enter 1 for CSV output / 2 for KAFKA topic output</description>
      </operator>
      <operator activated="true" class="blending:set_role" compatibility="10.5.000" expanded="true" height="82" name="Set Role for clarity" width="90" x="1184" y="34">
        <list key="set_roles">
          <parameter key="event_class" value="label"/>
          <parameter key="event_score" value="label"/>
        </list>
      </operator>
      <connect from_op="Retrieve server-crexdata-eu-no-auth" from_port="output" to_op="Multiply" to_port="input"/>
      <connect from_op="Multiply" from_port="output 1" to_op="Save to CSV or Kafka" to_port="input 2"/>
      <connect from_op="Multiply" from_port="output 2" to_op="Read Kafka Topic" to_port="connection"/>
      <connect from_op="Read Kafka Topic" from_port="output data" to_op="Select Attributes" to_port="example set input"/>
      <connect from_op="Select Attributes" from_port="example set output" to_op="Data to Documents" to_port="example set"/>
      <connect from_op="Data to Documents" from_port="documents" to_op="JSON To Data" to_port="documents 1"/>
      <connect from_op="JSON To Data" from_port="example set" to_op="Revelance Prediction" to_port="data"/>
      <connect from_op="Revelance Prediction" from_port="out" to_op="Save to CSV or Kafka" to_port="input 1"/>
      <connect from_op="Save to CSV or Kafka" from_port="output 1" to_op="Set Role for clarity" to_port="example set input"/>
      <connect from_op="Set Role for clarity" from_port="example set output" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <description align="center" color="yellow" colored="false" height="64" resized="true" width="483" x="520" y="18">Ensure Read Kafka Topic has tweet messages in json format with field name &amp;quot;tweet_text&amp;quot;.</description>
    </process>
  </operator>
</process>
